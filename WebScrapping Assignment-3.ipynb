{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "066e8160",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: selenium in c:\\users\\shyamanthularamakris\\anaconda3\\lib\\site-packages (4.10.0)\n",
      "Requirement already satisfied: trio~=0.17 in c:\\users\\shyamanthularamakris\\anaconda3\\lib\\site-packages (from selenium) (0.22.0)\n",
      "Requirement already satisfied: urllib3[socks]<3,>=1.26 in c:\\users\\shyamanthularamakris\\anaconda3\\lib\\site-packages (from selenium) (1.26.11)\n",
      "Requirement already satisfied: certifi>=2021.10.8 in c:\\users\\shyamanthularamakris\\anaconda3\\lib\\site-packages (from selenium) (2022.9.14)\n",
      "Requirement already satisfied: trio-websocket~=0.9 in c:\\users\\shyamanthularamakris\\anaconda3\\lib\\site-packages (from selenium) (0.10.2)\n",
      "Requirement already satisfied: attrs>=19.2.0 in c:\\users\\shyamanthularamakris\\anaconda3\\lib\\site-packages (from trio~=0.17->selenium) (21.4.0)\n",
      "Requirement already satisfied: cffi>=1.14 in c:\\users\\shyamanthularamakris\\anaconda3\\lib\\site-packages (from trio~=0.17->selenium) (1.15.1)\n",
      "Requirement already satisfied: sortedcontainers in c:\\users\\shyamanthularamakris\\anaconda3\\lib\\site-packages (from trio~=0.17->selenium) (2.4.0)\n",
      "Requirement already satisfied: sniffio in c:\\users\\shyamanthularamakris\\anaconda3\\lib\\site-packages (from trio~=0.17->selenium) (1.2.0)\n",
      "Requirement already satisfied: outcome in c:\\users\\shyamanthularamakris\\anaconda3\\lib\\site-packages (from trio~=0.17->selenium) (1.2.0)\n",
      "Requirement already satisfied: idna in c:\\users\\shyamanthularamakris\\anaconda3\\lib\\site-packages (from trio~=0.17->selenium) (3.3)\n",
      "Requirement already satisfied: exceptiongroup>=1.0.0rc9 in c:\\users\\shyamanthularamakris\\anaconda3\\lib\\site-packages (from trio~=0.17->selenium) (1.1.1)\n",
      "Requirement already satisfied: async-generator>=1.9 in c:\\users\\shyamanthularamakris\\anaconda3\\lib\\site-packages (from trio~=0.17->selenium) (1.10)\n",
      "Requirement already satisfied: wsproto>=0.14 in c:\\users\\shyamanthularamakris\\anaconda3\\lib\\site-packages (from trio-websocket~=0.9->selenium) (1.2.0)\n",
      "Requirement already satisfied: PySocks!=1.5.7,<2.0,>=1.5.6 in c:\\users\\shyamanthularamakris\\anaconda3\\lib\\site-packages (from urllib3[socks]<3,>=1.26->selenium) (1.7.1)\n",
      "Requirement already satisfied: pycparser in c:\\users\\shyamanthularamakris\\anaconda3\\lib\\site-packages (from cffi>=1.14->trio~=0.17->selenium) (2.21)\n",
      "Requirement already satisfied: h11<1,>=0.9.0 in c:\\users\\shyamanthularamakris\\anaconda3\\lib\\site-packages (from wsproto>=0.14->trio-websocket~=0.9->selenium) (0.14.0)\n",
      "Requirement already satisfied: webdriver-manager in c:\\users\\shyamanthularamakris\\anaconda3\\lib\\site-packages (3.8.6)\n",
      "Requirement already satisfied: tqdm in c:\\users\\shyamanthularamakris\\anaconda3\\lib\\site-packages (from webdriver-manager) (4.64.1)\n",
      "Requirement already satisfied: python-dotenv in c:\\users\\shyamanthularamakris\\anaconda3\\lib\\site-packages (from webdriver-manager) (1.0.0)\n",
      "Requirement already satisfied: requests in c:\\users\\shyamanthularamakris\\anaconda3\\lib\\site-packages (from webdriver-manager) (2.28.1)\n",
      "Requirement already satisfied: packaging in c:\\users\\shyamanthularamakris\\anaconda3\\lib\\site-packages (from webdriver-manager) (21.3)\n",
      "Requirement already satisfied: pyparsing!=3.0.5,>=2.0.2 in c:\\users\\shyamanthularamakris\\anaconda3\\lib\\site-packages (from packaging->webdriver-manager) (3.0.9)\n",
      "Requirement already satisfied: charset-normalizer<3,>=2 in c:\\users\\shyamanthularamakris\\anaconda3\\lib\\site-packages (from requests->webdriver-manager) (2.0.4)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in c:\\users\\shyamanthularamakris\\anaconda3\\lib\\site-packages (from requests->webdriver-manager) (2022.9.14)\n",
      "Requirement already satisfied: idna<4,>=2.5 in c:\\users\\shyamanthularamakris\\anaconda3\\lib\\site-packages (from requests->webdriver-manager) (3.3)\n",
      "Requirement already satisfied: urllib3<1.27,>=1.21.1 in c:\\users\\shyamanthularamakris\\anaconda3\\lib\\site-packages (from requests->webdriver-manager) (1.26.11)\n",
      "Requirement already satisfied: colorama in c:\\users\\shyamanthularamakris\\anaconda3\\lib\\site-packages (from tqdm->webdriver-manager) (0.4.5)\n"
     ]
    }
   ],
   "source": [
    "!pip install -U selenium\n",
    "!pip3 install webdriver-manager\n",
    "import pandas as pd\n",
    "import selenium\n",
    "from bs4 import BeautifulSoup\n",
    "import time\n",
    "from selenium import webdriver\n",
    "import requests\n",
    "import re\n",
    "from selenium.webdriver.common.by import By\n",
    "from selenium.webdriver.chrome.service import Service\n",
    "from selenium.common.exceptions import NoSuchElementException, StaleElementReferenceException\n",
    "from selenium.webdriver.common.by import By\n",
    "from selenium.webdriver.common.keys import Keys\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "68697ce6",
   "metadata": {},
   "source": [
    "Q1. Write a python program which searches all the product under a particular product from www.amazon.in. The \n",
    "product to be searched will be taken as input from user. For e.g. If user input is ‘guitar’. Then search for \n",
    "guitars."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "7b367cf5",
   "metadata": {},
   "outputs": [],
   "source": [
    "s=Service(ChromeDriverManager().install())\n",
    "driver = webdriver.Chrome(service=s)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "064e7333",
   "metadata": {},
   "outputs": [],
   "source": [
    "url = \"https://www.amazon.in/\"\n",
    "driver.get(url)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "286ecf0c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Enter the product that we want to search : guitar\n"
     ]
    }
   ],
   "source": [
    "user_input = input('Enter the product that we want to search : ')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "350e2ed8",
   "metadata": {},
   "outputs": [],
   "source": [
    "search = driver.find_element(By.ID,\"twotabsearchtextbox\")\n",
    "search\n",
    "\n",
    "search.send_keys(user_input)\n",
    "\n",
    "search_btn = driver.find_element(By.XPATH,\"//div[@class='nav-search-submit nav-sprite']/span/input\")\n",
    "\n",
    "search_btn.click()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9eb9848e",
   "metadata": {},
   "source": [
    "Q2.In the above question, now scrape the following details of each product listed in first 3 pages of your search \n",
    "results and save it in a data frame and csv. In case if any product has less than 3 pages in search results then \n",
    "scrape all the products available under that product name. Details to be scraped are: \"Brand \n",
    "Name\", \"Name of the Product\", \"Price\", \"Return/Exchange\", \"Expected Delivery\", \"Availability\" and \n",
    "“Product URL”. In case, if any of the details are missing for any of the product then replace it by “-“."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "7569600c",
   "metadata": {},
   "outputs": [],
   "source": [
    "urls = []    \n",
    "for i in range(0,3):   \n",
    "    page_url = driver.find_elements(By.XPATH,\"//a[@class='a-link-normal s-underline-text s-underline-link-text s-link-style a-text-normal']\")\n",
    "    for i in page_url:\n",
    "        urls.append(i.get_attribute(\"href\"))\n",
    "next_btn = driver.find_elements(By.XPATH,\"//li[@class='a-last']/a\")\n",
    "time.sleep(3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "d2352b94",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "183"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(urls)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "804bef84",
   "metadata": {},
   "outputs": [],
   "source": [
    "Brand_Name = [] \n",
    "Product_Name = [] \n",
    "Price = [] \n",
    "Exchange = [] \n",
    "Expected_delivery = [] \n",
    "Availability = []"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "75f5b0bf",
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in urls:\n",
    "    driver.get(i)\n",
    "    time.sleep(3)\n",
    "    \n",
    "    try:\n",
    "        brand = driver.find_element(By.XPATH,\"//div[@class='a-section a-spacing-small a-spacing-top-small']/table/tbody/tr/td[2]\")\n",
    "        Brand_Name.append(brand.text)\n",
    "    except NoSuchElementException:\n",
    "        Brand_Name.append('-')\n",
    "    try:\n",
    "        name = driver.find_element(By.XPATH,\"//span[@id='productTitle']\")\n",
    "        Product_Name.append(name.text)\n",
    "    except NoSuchElementException:\n",
    "        Product_Name.append('-')\n",
    "    try:\n",
    "        price = driver.find_element(By.XPATH,\"//span[@class='a-price aok-align-center reinventPricePriceToPayMargin priceToPay']\")\n",
    "        Price.append(price.text)\n",
    "    except NoSuchElementException:\n",
    "        Price.append('-')\n",
    "    try:\n",
    "        Return = driver.find_element(By.XPATH,\"//li[3][@class='a-carousel-card tw-scroll-carousel-element']/div/span/div[2]/span\")\n",
    "        Exchange.append(Return.text)\n",
    "    except NoSuchElementException:\n",
    "        Exchange.append('-')    \n",
    "    try:\n",
    "        exp_del = driver.find_element(By.XPATH,\"//div[1][@class='a-spacing-base']/span/span\")\n",
    "        Expected_delivery.append(exp_del.text)\n",
    "    except NoSuchElementException:\n",
    "        Expected_delivery.append('-')\n",
    "    try:\n",
    "        availability = driver.find_element(By.XPATH,\"//span[@class='a-size-medium a-color-success']\")\n",
    "        Availability.append(availability.text)\n",
    "    except NoSuchElementException:\n",
    "        Availability.append('-')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "bcd3a122",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "183 183 183 183 183 183\n"
     ]
    }
   ],
   "source": [
    "print(len(Brand_Name),\n",
    "      len(Product_Name),\n",
    "      len(Price),\n",
    "      len(Exchange),\n",
    "      len(Expected_delivery),\n",
    "      len(Availability))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "8b009317",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Brand Name</th>\n",
       "      <th>Product Name</th>\n",
       "      <th>Price</th>\n",
       "      <th>Return/Exchange</th>\n",
       "      <th>Expected Delivery</th>\n",
       "      <th>Availability</th>\n",
       "      <th>Product URL</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Kadence</td>\n",
       "      <td>Kadence Frontier guitar with Online Guitar lea...</td>\n",
       "      <td>₹4,999</td>\n",
       "      <td>7 days Replacement</td>\n",
       "      <td>Wednesday, 14 June</td>\n",
       "      <td>In stock</td>\n",
       "      <td>https://www.amazon.in/sspa/click?ie=UTF8&amp;spc=M...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>DEVICE OF URBAN INFOTECH</td>\n",
       "      <td>DEVICE OF URBAN INFOTECH 41 inch Acoustic Guit...</td>\n",
       "      <td>₹5,448</td>\n",
       "      <td>7 days Returnable</td>\n",
       "      <td>Saturday, 17 June</td>\n",
       "      <td>In stock</td>\n",
       "      <td>https://www.amazon.in/sspa/click?ie=UTF8&amp;spc=M...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Henrix</td>\n",
       "      <td>Henrix 38C 38 Inch Cutaway Acoustic Guitar Wit...</td>\n",
       "      <td>₹2,999</td>\n",
       "      <td>7 days Replacement</td>\n",
       "      <td>Thursday, 15 June</td>\n",
       "      <td>In stock</td>\n",
       "      <td>https://www.amazon.in/sspa/click?ie=UTF8&amp;spc=M...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>VAULT</td>\n",
       "      <td>Vault DA40 41 Inch Premium Solid Spruce-Top Dr...</td>\n",
       "      <td>₹6,934</td>\n",
       "      <td>7 days Replacement</td>\n",
       "      <td>Saturday, 17 June</td>\n",
       "      <td>In stock</td>\n",
       "      <td>https://www.amazon.in/sspa/click?ie=UTF8&amp;spc=M...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>JUAREZ</td>\n",
       "      <td>Juârez Acoustic Guitar, 38 Inch Cutaway, 038C ...</td>\n",
       "      <td>₹1,999</td>\n",
       "      <td>7 days Replacement</td>\n",
       "      <td>Friday, 16 June</td>\n",
       "      <td>In stock</td>\n",
       "      <td>https://www.amazon.in/Juarez-Acoustic-Cutaway-...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>178</th>\n",
       "      <td>Kadence</td>\n",
       "      <td>Kadence Frontier Jumbo Semi Acoustic Guitar Wi...</td>\n",
       "      <td>₹6,899</td>\n",
       "      <td>7 days Replacement</td>\n",
       "      <td>Friday, 16 June</td>\n",
       "      <td>In stock</td>\n",
       "      <td>https://www.amazon.in/Kadence-Frontier-Acousti...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>179</th>\n",
       "      <td>IMAGINEA</td>\n",
       "      <td>Imaginea® 41 Inch Acoustic Guitar Semi Wood an...</td>\n",
       "      <td>₹4,999</td>\n",
       "      <td>7 days Returnable</td>\n",
       "      <td>Saturday, 17 June</td>\n",
       "      <td>In stock</td>\n",
       "      <td>https://www.amazon.in/sspa/click?ie=UTF8&amp;spc=M...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>180</th>\n",
       "      <td>Guitar Bro</td>\n",
       "      <td>GUITAR BRO - COMBO (Black Acoustic Guitar for ...</td>\n",
       "      <td>₹8,999</td>\n",
       "      <td>-</td>\n",
       "      <td>17 - 20 June</td>\n",
       "      <td>In stock</td>\n",
       "      <td>https://www.amazon.in/sspa/click?ie=UTF8&amp;spc=M...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>181</th>\n",
       "      <td>ESH Creations</td>\n",
       "      <td>ESH Creations E39CHEQ High Gloss Semi Acoustic...</td>\n",
       "      <td>₹5,397</td>\n",
       "      <td>7 days Replacement</td>\n",
       "      <td>Saturday, 17 June</td>\n",
       "      <td>-</td>\n",
       "      <td>https://www.amazon.in/sspa/click?ie=UTF8&amp;spc=M...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>182</th>\n",
       "      <td>DEVICE OF URBAN INFOTECH</td>\n",
       "      <td>DEVICE OF URBAN INFOTECH 24Inch Ukulele Concer...</td>\n",
       "      <td>₹3,549</td>\n",
       "      <td>7 days Returnable</td>\n",
       "      <td>Saturday, 17 June</td>\n",
       "      <td>In stock</td>\n",
       "      <td>https://www.amazon.in/sspa/click?ie=UTF8&amp;spc=M...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>183 rows × 7 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                   Brand Name  \\\n",
       "0                     Kadence   \n",
       "1    DEVICE OF URBAN INFOTECH   \n",
       "2                      Henrix   \n",
       "3                       VAULT   \n",
       "4                      JUAREZ   \n",
       "..                        ...   \n",
       "178                   Kadence   \n",
       "179                  IMAGINEA   \n",
       "180                Guitar Bro   \n",
       "181             ESH Creations   \n",
       "182  DEVICE OF URBAN INFOTECH   \n",
       "\n",
       "                                          Product Name   Price  \\\n",
       "0    Kadence Frontier guitar with Online Guitar lea...  ₹4,999   \n",
       "1    DEVICE OF URBAN INFOTECH 41 inch Acoustic Guit...  ₹5,448   \n",
       "2    Henrix 38C 38 Inch Cutaway Acoustic Guitar Wit...  ₹2,999   \n",
       "3    Vault DA40 41 Inch Premium Solid Spruce-Top Dr...  ₹6,934   \n",
       "4    Juârez Acoustic Guitar, 38 Inch Cutaway, 038C ...  ₹1,999   \n",
       "..                                                 ...     ...   \n",
       "178  Kadence Frontier Jumbo Semi Acoustic Guitar Wi...  ₹6,899   \n",
       "179  Imaginea® 41 Inch Acoustic Guitar Semi Wood an...  ₹4,999   \n",
       "180  GUITAR BRO - COMBO (Black Acoustic Guitar for ...  ₹8,999   \n",
       "181  ESH Creations E39CHEQ High Gloss Semi Acoustic...  ₹5,397   \n",
       "182  DEVICE OF URBAN INFOTECH 24Inch Ukulele Concer...  ₹3,549   \n",
       "\n",
       "        Return/Exchange   Expected Delivery Availability  \\\n",
       "0    7 days Replacement  Wednesday, 14 June     In stock   \n",
       "1     7 days Returnable   Saturday, 17 June     In stock   \n",
       "2    7 days Replacement   Thursday, 15 June     In stock   \n",
       "3    7 days Replacement   Saturday, 17 June     In stock   \n",
       "4    7 days Replacement     Friday, 16 June     In stock   \n",
       "..                  ...                 ...          ...   \n",
       "178  7 days Replacement     Friday, 16 June     In stock   \n",
       "179   7 days Returnable   Saturday, 17 June     In stock   \n",
       "180                   -        17 - 20 June     In stock   \n",
       "181  7 days Replacement   Saturday, 17 June            -   \n",
       "182   7 days Returnable   Saturday, 17 June     In stock   \n",
       "\n",
       "                                           Product URL  \n",
       "0    https://www.amazon.in/sspa/click?ie=UTF8&spc=M...  \n",
       "1    https://www.amazon.in/sspa/click?ie=UTF8&spc=M...  \n",
       "2    https://www.amazon.in/sspa/click?ie=UTF8&spc=M...  \n",
       "3    https://www.amazon.in/sspa/click?ie=UTF8&spc=M...  \n",
       "4    https://www.amazon.in/Juarez-Acoustic-Cutaway-...  \n",
       "..                                                 ...  \n",
       "178  https://www.amazon.in/Kadence-Frontier-Acousti...  \n",
       "179  https://www.amazon.in/sspa/click?ie=UTF8&spc=M...  \n",
       "180  https://www.amazon.in/sspa/click?ie=UTF8&spc=M...  \n",
       "181  https://www.amazon.in/sspa/click?ie=UTF8&spc=M...  \n",
       "182  https://www.amazon.in/sspa/click?ie=UTF8&spc=M...  \n",
       "\n",
       "[183 rows x 7 columns]"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Product = pd.DataFrame({})\n",
    "Product[\"Brand Name\"] = Brand_Name\n",
    "Product[\"Product Name\"] = Product_Name\n",
    "Product[\"Price\"] = Price\n",
    "Product[\"Return/Exchange\"] = Exchange\n",
    "Product[\"Expected Delivery\"] = Expected_delivery\n",
    "Product[\"Availability\"] = Availability\n",
    "Product[\"Product URL\"] = urls\n",
    "Product"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "bf61c341",
   "metadata": {},
   "outputs": [],
   "source": [
    "Product.to_csv(\"Product.csv\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e7df3af6",
   "metadata": {},
   "source": [
    "Q3.Write a python program to access the search bar and search button on images.google.com and scrape 10 \n",
    "images each for keywords ‘fruits’, ‘cars’ and ‘Machine Learning’, ‘Guitar’, ‘Cakes’. \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "04d98824",
   "metadata": {},
   "outputs": [],
   "source": [
    "from webdriver_manager.chrome import ChromeDriverManager\n",
    "driver = webdriver.Chrome(service=Service(ChromeDriverManager().install()))\n",
    "url = \"https://images.google.com/\" \n",
    "urls = []    \n",
    "data = [] "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "95c214d2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Downloading 0 of 10 images\n",
      "Downloading 1 of 10 images\n",
      "Downloading 2 of 10 images\n",
      "Downloading 3 of 10 images\n",
      "Downloading 4 of 10 images\n",
      "Downloading 5 of 10 images\n",
      "Downloading 6 of 10 images\n",
      "Downloading 7 of 10 images\n",
      "Downloading 8 of 10 images\n",
      "Downloading 9 of 10 images\n"
     ]
    }
   ],
   "source": [
    "#Fruits images to download\n",
    "search_item = [\"fruits\"]\n",
    "for item in search_item:\n",
    "    driver.get(url)  \n",
    "    time.sleep(5)\n",
    "    \n",
    "    # Finding webelement for search_bar\n",
    "    search_bar = driver.find_element(By.XPATH,\"//textarea[@class='gLFyf']\")\n",
    "    \n",
    "    # Sending keys to get the keyword for search bar\n",
    "    search_bar.send_keys(search_item)\n",
    "    # Clicking on search button\n",
    "    search_button =driver.find_element(By.XPATH,\"//button[@class='Tg7LZd']\").click()\n",
    "    \n",
    "    # Scrolling down the webpage to get some more images\n",
    "    for _ in range(100):\n",
    "        driver.execute_script(\"window.scrollBy(0,50)\")\n",
    "        \n",
    "        imgs = driver.find_elements(By.XPATH,\"//img[@class='rg_i Q4LuWd']\")\n",
    "    img_url = []\n",
    "    for image in imgs:\n",
    "        source = image.get_attribute('src')\n",
    "        if source is not None:\n",
    "                if(source[0:4] == 'http'):\n",
    "                    img_url.append(source)\n",
    "    for i in img_url[:10]:\n",
    "        urls.append(i)\n",
    "                    \n",
    "for i in range(len(urls)):\n",
    "    if i >= 10:\n",
    "        break\n",
    "    print(\"Downloading {0} of {1} images\" .format(i, 10))\n",
    "    response = requests.get(urls[i])\n",
    "\n",
    "   "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "cb434d2f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Downloading 0 of 10 images\n",
      "Downloading 1 of 10 images\n",
      "Downloading 2 of 10 images\n",
      "Downloading 3 of 10 images\n",
      "Downloading 4 of 10 images\n",
      "Downloading 5 of 10 images\n",
      "Downloading 6 of 10 images\n",
      "Downloading 7 of 10 images\n",
      "Downloading 8 of 10 images\n",
      "Downloading 9 of 10 images\n"
     ]
    }
   ],
   "source": [
    "#cars images to download\n",
    "search_item = [\"cars\"]\n",
    "for item in search_item:\n",
    "    driver.get(url)  \n",
    "    time.sleep(5)\n",
    "    \n",
    "    # Finding webelement for search_bar\n",
    "    search_bar = driver.find_element(By.XPATH,\"//textarea[@class='gLFyf']\")\n",
    "    \n",
    "    # Sending keys to get the keyword for search bar\n",
    "    search_bar.send_keys(search_item)\n",
    "    # Clicking on search button\n",
    "    search_button =driver.find_element(By.XPATH,\"//button[@class='Tg7LZd']\").click()\n",
    "    \n",
    "    # Scrolling down the webpage to get some more images\n",
    "    for _ in range(100):\n",
    "        driver.execute_script(\"window.scrollBy(0,50)\")\n",
    "        \n",
    "        imgs = driver.find_elements(By.XPATH,\"//img[@class='rg_i Q4LuWd']\")\n",
    "    img_url = []\n",
    "    for image in imgs:\n",
    "        source = image.get_attribute('src')\n",
    "        if source is not None:\n",
    "                if(source[0:4] == 'http'):\n",
    "                    img_url.append(source)\n",
    "    for i in img_url[:10]:\n",
    "        urls.append(i)\n",
    "                    \n",
    "for i in range(len(urls)):\n",
    "    if i >= 10:\n",
    "        break\n",
    "    print(\"Downloading {0} of {1} images\" .format(i, 10))\n",
    "    response = requests.get(urls[i])\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "99d10bb0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Downloading 0 of 10 images\n",
      "Downloading 1 of 10 images\n",
      "Downloading 2 of 10 images\n",
      "Downloading 3 of 10 images\n",
      "Downloading 4 of 10 images\n",
      "Downloading 5 of 10 images\n",
      "Downloading 6 of 10 images\n",
      "Downloading 7 of 10 images\n",
      "Downloading 8 of 10 images\n",
      "Downloading 9 of 10 images\n"
     ]
    }
   ],
   "source": [
    "search_item = [\"Guitar\"]\n",
    "for item in search_item:\n",
    "    driver.get(url)  \n",
    "    time.sleep(5)\n",
    "    \n",
    "    # Finding webelement for search_bar\n",
    "    search_bar = driver.find_element(By.XPATH,\"//textarea[@class='gLFyf']\")\n",
    "    \n",
    "    # Sending keys to get the keyword for search bar\n",
    "    search_bar.send_keys(search_item)\n",
    "    # Clicking on search button\n",
    "    search_button =driver.find_element(By.XPATH,\"//button[@class='Tg7LZd']\").click()\n",
    "    \n",
    "    # Scrolling down the webpage to get some more images\n",
    "    for _ in range(100):\n",
    "        driver.execute_script(\"window.scrollBy(0,50)\")\n",
    "        \n",
    "        imgs = driver.find_elements(By.XPATH,\"//img[@class='rg_i Q4LuWd']\")\n",
    "    img_url = []\n",
    "    for image in imgs:\n",
    "        source = image.get_attribute('src')\n",
    "        if source is not None:\n",
    "                if(source[0:4] == 'http'):\n",
    "                    img_url.append(source)\n",
    "    for i in img_url[:10]:\n",
    "        urls.append(i)\n",
    "                    \n",
    "for i in range(len(urls)):\n",
    "    if i >= 10:\n",
    "        break\n",
    "    print(\"Downloading {0} of {1} images\" .format(i, 10))\n",
    "    response = requests.get(urls[i])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "875737f6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Downloading 0 of 10 images\n",
      "Downloading 1 of 10 images\n",
      "Downloading 2 of 10 images\n",
      "Downloading 3 of 10 images\n",
      "Downloading 4 of 10 images\n",
      "Downloading 5 of 10 images\n",
      "Downloading 6 of 10 images\n",
      "Downloading 7 of 10 images\n",
      "Downloading 8 of 10 images\n",
      "Downloading 9 of 10 images\n"
     ]
    }
   ],
   "source": [
    "search_item = [\"Machine Learning\"]\n",
    "for item in search_item:\n",
    "    driver.get(url)  \n",
    "    time.sleep(5)\n",
    "    \n",
    "    # Finding webelement for search_bar\n",
    "    search_bar = driver.find_element(By.XPATH,\"//textarea[@class='gLFyf']\")\n",
    "    \n",
    "    # Sending keys to get the keyword for search bar\n",
    "    search_bar.send_keys(search_item)\n",
    "    # Clicking on search button\n",
    "    search_button =driver.find_element(By.XPATH,\"//button[@class='Tg7LZd']\").click()\n",
    "    \n",
    "    # Scrolling down the webpage to get some more images\n",
    "    for _ in range(100):\n",
    "        driver.execute_script(\"window.scrollBy(0,50)\")\n",
    "        \n",
    "        imgs = driver.find_elements(By.XPATH,\"//img[@class='rg_i Q4LuWd']\")\n",
    "    img_url = []\n",
    "    for image in imgs:\n",
    "        source = image.get_attribute('src')\n",
    "        if source is not None:\n",
    "                if(source[0:4] == 'http'):\n",
    "                    img_url.append(source)\n",
    "    for i in img_url[:10]:\n",
    "        urls.append(i)\n",
    "                    \n",
    "for i in range(len(urls)):\n",
    "    if i >= 10:\n",
    "        break\n",
    "    print(\"Downloading {0} of {1} images\" .format(i, 10))\n",
    "    response = requests.get(urls[i])\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "8b316e33",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Downloading 0 of 10 images\n",
      "Downloading 1 of 10 images\n",
      "Downloading 2 of 10 images\n",
      "Downloading 3 of 10 images\n",
      "Downloading 4 of 10 images\n",
      "Downloading 5 of 10 images\n",
      "Downloading 6 of 10 images\n",
      "Downloading 7 of 10 images\n",
      "Downloading 8 of 10 images\n",
      "Downloading 9 of 10 images\n"
     ]
    }
   ],
   "source": [
    "search_item = [\"cakes\"]\n",
    "for item in search_item:\n",
    "    driver.get(url)  \n",
    "    time.sleep(5)\n",
    "    \n",
    "    # Finding webelement for search_bar\n",
    "    search_bar = driver.find_element(By.XPATH,\"//textarea[@class='gLFyf']\")\n",
    "    \n",
    "    # Sending keys to get the keyword for search bar\n",
    "    search_bar.send_keys(search_item)\n",
    "    # Clicking on search button\n",
    "    search_button =driver.find_element(By.XPATH,\"//button[@class='Tg7LZd']\").click()\n",
    "    \n",
    "    # Scrolling down the webpage to get some more images\n",
    "    for _ in range(100):\n",
    "        driver.execute_script(\"window.scrollBy(0,50)\")\n",
    "        \n",
    "        imgs = driver.find_elements(By.XPATH,\"//img[@class='rg_i Q4LuWd']\")\n",
    "    img_url = []\n",
    "    for image in imgs:\n",
    "        source = image.get_attribute('src')\n",
    "        if source is not None:\n",
    "                if(source[0:4] == 'http'):\n",
    "                    img_url.append(source)\n",
    "    for i in img_url[:10]:\n",
    "        urls.append(i)\n",
    "                    \n",
    "for i in range(len(urls)):\n",
    "    if i >= 10:\n",
    "        break\n",
    "    print(\"Downloading {0} of {1} images\" .format(i, 10))\n",
    "    response = requests.get(urls[i])\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3a8f31d0",
   "metadata": {},
   "source": [
    "Q4.Write a python program to search for a smartphone(e.g.: Oneplus Nord, pixel 4A, etc.) on www.flipkart.com\n",
    "and scrape following details for all the search results displayed on 1st page. Details to be scraped: “Brand \n",
    "Name”, “Smartphone name”, “Colour”, “RAM”, “Storage(ROM)”, “Primary Camera”, \n",
    "“Secondary Camera”, “Display Size”, “Battery Capacity”, “Price”, “Product URL”. Incase if any of the \n",
    "details is missing then replace it by “- “. Save your results in a dataframe and CSV."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 239,
   "id": "c52a398d",
   "metadata": {},
   "outputs": [],
   "source": [
    "s=Service(ChromeDriverManager().install())\n",
    "driver = webdriver.Chrome(service=s)\n",
    "url = \"https://www.flipkart.com/\"\n",
    "driver.get(url)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 240,
   "id": "dd419033",
   "metadata": {},
   "outputs": [],
   "source": [
    "search_bar = driver.find_element(By.XPATH,\"//input[@class='_3704LK']\")\n",
    "\n",
    "# sending keys to search product\n",
    "search_bar.send_keys(\"pixel 4A\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 244,
   "id": "7563f2f0",
   "metadata": {},
   "outputs": [],
   "source": [
    "search_bar=driver.find_element(By.XPATH,'/html/body/div[1]/div/div[1]/div[1]/div[2]/div[2]/form/div/button')\n",
    "search_bar.click()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 245,
   "id": "4cb08b31",
   "metadata": {},
   "outputs": [],
   "source": [
    "page1_url = []\n",
    "urls = driver.find_elements(By.XPATH,\"//a[@class='_1fQZEK']\")\n",
    "for url in urls:\n",
    "    page1_url.append(url.get_attribute('href'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 246,
   "id": "d620f2a6",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "5"
      ]
     },
     "execution_count": 246,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(page1_url)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 247,
   "id": "ac927738",
   "metadata": {},
   "outputs": [],
   "source": [
    "Smartphones = ({})\n",
    "Smartphones['Brand'] = []\n",
    "Smartphones['Phone name'] = []\n",
    "Smartphones['Colour'] = []\n",
    "Smartphones['RAM'] = []\n",
    "Smartphones['Storage(ROM)'] = []\n",
    "Smartphones['Primary Camera'] = []\n",
    "Smartphones['Secondary Camera'] = []\n",
    "Smartphones['Display Size'] = []\n",
    "Smartphones['Battery Capacity'] = []\n",
    "Smartphones['Price'] = []\n",
    "Smartphones['URL'] = []"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 248,
   "id": "13feb6b4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Scraping URL =  https://www.flipkart.com/google-pixel-6a-charcoal-128-gb/p/itme5ae89135d44e?pid=MOBGFKX5YUXD74Z3&lid=LSTMOBGFKX5YUXD74Z3MXA2OB&marketplace=FLIPKART&q=pixel+4A&store=tyy%2F4io&srno=s_1_1&otracker=search&otracker1=search&fm=organic&iid=1ec7fd02-e91c-4be3-9be0-0ab6608af976.MOBGFKX5YUXD74Z3.SEARCH&ppt=hp&ppn=homepage&ssid=jltnpvyw2o0000001686393510326&qH=9b26a23b2cff510d\n",
      "Scraping URL =  https://www.flipkart.com/google-pixel-6a-chalk-128-gb/p/itme5ae89135d44e?pid=MOBGFWEZ5SKU84Z8&lid=LSTMOBGFWEZ5SKU84Z8FXPB45&marketplace=FLIPKART&q=pixel+4A&store=tyy%2F4io&srno=s_1_2&otracker=search&otracker1=search&fm=organic&iid=1ec7fd02-e91c-4be3-9be0-0ab6608af976.MOBGFWEZ5SKU84Z8.SEARCH&ppt=hp&ppn=homepage&ssid=jltnpvyw2o0000001686393510326&qH=9b26a23b2cff510d\n",
      "Scraping URL =  https://www.flipkart.com/google-pixel-3a-just-black-64-gb/p/itmdb899b4e1bba7?pid=MOBGPAFV9PVXZCHD&lid=LSTMOBGPAFV9PVXZCHDAW1C4L&marketplace=FLIPKART&q=pixel+4A&store=tyy%2F4io&srno=s_1_3&otracker=search&otracker1=search&fm=organic&iid=1ec7fd02-e91c-4be3-9be0-0ab6608af976.MOBGPAFV9PVXZCHD.SEARCH&ppt=hp&ppn=homepage&ssid=jltnpvyw2o0000001686393510326&qH=9b26a23b2cff510d\n",
      "Scraping URL =  https://www.flipkart.com/google-pixel-3-not-pink-128-gb/p/itmfbuyqxkruzg7j?pid=MOBF9GAPZPV9S3YH&lid=LSTMOBF9GAPZPV9S3YHFX0IAW&marketplace=FLIPKART&q=pixel+4A&store=tyy%2F4io&srno=s_1_4&otracker=search&otracker1=search&fm=organic&iid=1ec7fd02-e91c-4be3-9be0-0ab6608af976.MOBF9GAPZPV9S3YH.SEARCH&ppt=hp&ppn=homepage&ssid=jltnpvyw2o0000001686393510326&qH=9b26a23b2cff510d\n",
      "Scraping URL =  https://www.flipkart.com/google-pixel-3a-purple-ish-64-gb/p/itmdb899b4e1bba7?pid=MOBGPDB2EYPZYN9G&lid=LSTMOBGPDB2EYPZYN9GJH6OCO&marketplace=FLIPKART&q=pixel+4A&store=tyy%2F4io&srno=s_1_5&otracker=search&otracker1=search&fm=organic&iid=1ec7fd02-e91c-4be3-9be0-0ab6608af976.MOBGPDB2EYPZYN9G.SEARCH&ppt=hp&ppn=homepage&ssid=jltnpvyw2o0000001686393510326&qH=9b26a23b2cff510d\n"
     ]
    }
   ],
   "source": [
    "for url in page1_url:\n",
    "    driver.get(url)\n",
    "    print(\"Scraping URL = \",url)\n",
    "    Smartphones['URL'].append(url)\n",
    "    time.sleep(2)\n",
    "    \n",
    "    \n",
    "    #clicking on read more button to get more information\n",
    "    try:\n",
    "        read_more = driver.find_element(By.XPATH,\"//button[@class='_2KpZ6l _1FH0tX']\")\n",
    "        read_more.click()\n",
    "    except NoSuchElementException:\n",
    "        print(\"Exception occured while moving to next page\")\n",
    "    \n",
    "    #scraping brand name of smartphone\n",
    "    try:\n",
    "        brand_tags = driver.find_element(By.XPATH,\"//span[@class='B_NuCI']\")\n",
    "        Smartphones['Brand'].append(brand_tags.text.split()[0])\n",
    "    except NoSuchElementException:\n",
    "        Smartphones['Brand'].append('-')\n",
    "    \n",
    "    \n",
    "    # scraping name of smartphones\n",
    "    try:\n",
    "        name_tags = driver.find_element(By.XPATH,\"//div[@class='_3k-BhJ'][1]/table/tbody/tr[3]/td[2]/ul/li\")\n",
    "        Smartphones['Phone name'].append(name_tags.text)\n",
    "    except NoSuchElementException:\n",
    "        Smartphones['Phone name'].append('-')\n",
    "        \n",
    "    #scraping colour of smartphone\n",
    "    try:\n",
    "        color_tags = driver.find_element(By.XPATH,\"//div[@class='_3k-BhJ'][1]/table/tbody/tr[4]/td[2]/ul/li\")\n",
    "        Smartphones['Colour'].append(color_tags.text)\n",
    "    except NoSuchElementException:\n",
    "        Smartphones['Colour'].append('-')\n",
    "        \n",
    "    # scraping RAM data of smartphone\n",
    "    try:\n",
    "        ram_tags = driver.find_element(By.XPATH,\"//div[@class='_3k-BhJ'][4]/table[1]/tbody/tr[2]/td[2]/ul/li\")\n",
    "        Smartphones['RAM'].append(ram_tags.text)\n",
    "    except NoSuchElementException:\n",
    "        Smartphones['RAM'].append('-')\n",
    "        \n",
    "    #scraping ROM data of smartphones\n",
    "    try:\n",
    "        rom = driver.find_element(By.XPATH,\"//div[@class='_3k-BhJ'][4]/table[1]/tbody/tr[1]/td[2]/ul/li\")\n",
    "        Smartphones['Storage(ROM)'].append(rom.text)\n",
    "    except NoSuchElementException:\n",
    "        Smartphones['Storage(ROM)'].append('-')\n",
    "        \n",
    "    # scraping  Primary camera data of smartphone\n",
    "    try:\n",
    "        pri =driver.find_element(By.XPATH,\"//div[@class='_3k-BhJ'][5]/table[1]/tbody/tr[2]/td[2]/ul/li\")\n",
    "        Smartphones['Primary Camera'].append(pri.text)\n",
    "    except NoSuchElementException:\n",
    "        Smartphones['Primary Camera'].append('-')\n",
    "        \n",
    "    # scraping secondary camera data of smartphone\n",
    "    try:\n",
    "        sec = driver.find_element(By.XPATH,\"//div[@class='_3k-BhJ'][5]/table[1]/tbody/tr[6]/td[1]\")\n",
    "        if sec != 'Secondary Camera' :\n",
    "            if driver.find_element(By.XPATH,\"//div[@class='_3k-BhJ'][5]/table[1]/tbody/tr[5]/td[1]\").text == \"Secondary Camera\":\n",
    "                sec_cam =driver.find_element(By.XPATH,\"//div[@class='_3k-BhJ'][5]/table[1]/tbody/tr[5]/td[2]/ul/li\")\n",
    "            else :\n",
    "                raise NoSuchElementException\n",
    "        else :\n",
    "            sec_cam = driver.find_element(By.XPATH,\"//div[@class='_3k-BhJ'][5]/table[1]/tbody/tr[6]/td[2]/ul/li\")\n",
    "        Smartphones['Secondary Camera'].append(sec_cam.text)\n",
    "    except NoSuchElementException:\n",
    "        Smartphones['Secondary Camera'].append('-')\n",
    "        \n",
    "    \n",
    "    #scraping display size data of smartphone\n",
    "    try:\n",
    "        disp = driver.find_element(By.XPATH,\"//div[@class='_3k-BhJ'][2]/div\")\n",
    "        if disp.text != 'Display Features' : raise NoSuchElementException\n",
    "        disp_size = driver.find_element(By.XPATH,\"//div[@class='_3k-BhJ'][2]/table[1]/tbody/tr[1]/td[2]/ul/li\")\n",
    "        Smartphones['Display Size'].append(disp_size.text)\n",
    "    except NoSuchElementException:\n",
    "        Smartphones['Display Size'].append('-')\n",
    "        \n",
    " # scraping the battery capacity of smartphone\n",
    "    try:\n",
    "        if driver.find_element(By.XPATH,\"//div[@class='_3k-BhJ'][10]/div\").text != \"Battery & Power Features\" :\n",
    "            if driver.find_element(By.XPATH,\"//div[@class='_3k-BhJ'][9]/div\").text == \"Battery & Power Features\" :\n",
    "                bat_tags = driver.find_element(By.XPATH,\"//div[@class='_3k-BhJ'][9]/table/tbody/tr/td[1]\")\n",
    "                if bat_tags.text != \"Battery Capacity\" : raise NoSuchElementException\n",
    "                bat_capa = driver.find_element(By.XPATH,\"//div[@class='_3k-BhJ'][9]/table/tbody/tr/td[2]/ul/li\")\n",
    "            elif driver.find_element(By.XPATH,\"//div[@class='_3k-BhJ'][8]/div\").text == \"Battery & Power Features\" :\n",
    "                bat_tags = driver.find_element(By.XPATH,\"//div[@class='_3k-BhJ'][8]/table/tbody/tr/td[1]\")\n",
    "                if bat_tags.text != \"Battery Capacity\" : raise NoSuchElementException\n",
    "                bat_capa = driver.find_element(By.XPATH,\"//div[@class='_3k-BhJ'][8]/table/tbody/tr/td[2]/ul/li\")\n",
    "            else:\n",
    "                raise NoSuchElementException\n",
    "        else :\n",
    "            bat_tags = driver.find_element(By.XPATH,\"//div[@class='_3k-BhJ'][10]/table/tbody/tr/td[1]\")\n",
    "            if bat_tags.text != \"Battery Capacity\" : raise NoSuchElementException\n",
    "            bat_capa = driver.find_element(By.XPATH,\"//div[@class='_3k-BhJ'][10]/table/tbody/tr/td[2]/ul/li\")\n",
    "        Smartphones['Battery Capacity'].append(bat_capa.text)\n",
    "    except NoSuchElementException:\n",
    "        Smartphones['Battery Capacity'].append('-')\n",
    "    \n",
    "    \n",
    "    \n",
    "    \n",
    "    # scraping price of smartphone\n",
    "    try:\n",
    "        price_tags = driver.find_element(By.XPATH,\"//div[@class='_30jeq3 _16Jk6d']\")\n",
    "        Smartphones['Price'].append(price_tags.text)\n",
    "    except NoSuchElementException:\n",
    "          Smartphones['Price'].append('-')      "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 250,
   "id": "db9d15a1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "5 5 5 5 5 5 5 5 5 5 5\n"
     ]
    }
   ],
   "source": [
    "print(len(Smartphones['Brand']),\n",
    "      len(Smartphones['Phone name']),\n",
    "      len(Smartphones['Colour']),\n",
    "      len(Smartphones['RAM']),\n",
    "      len(Smartphones['Storage(ROM)']),\n",
    "      len(Smartphones['Primary Camera']),len(Smartphones['Secondary Camera']),len(Smartphones['Display Size']),\n",
    "      len(Smartphones['Battery Capacity']),len(Smartphones['Price']),len(Smartphones['URL']))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 251,
   "id": "96488ed2",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Brand</th>\n",
       "      <th>Phone name</th>\n",
       "      <th>Colour</th>\n",
       "      <th>RAM</th>\n",
       "      <th>Storage(ROM)</th>\n",
       "      <th>Primary Camera</th>\n",
       "      <th>Secondary Camera</th>\n",
       "      <th>Display Size</th>\n",
       "      <th>Battery Capacity</th>\n",
       "      <th>Price</th>\n",
       "      <th>URL</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Google</td>\n",
       "      <td>Pixel 6a</td>\n",
       "      <td>Charcoal</td>\n",
       "      <td>6 GB</td>\n",
       "      <td>128 GB</td>\n",
       "      <td>12.2MP + 12MP</td>\n",
       "      <td>8MP Front Camera</td>\n",
       "      <td>15.6 cm (6.14 inch)</td>\n",
       "      <td>4410 mAh</td>\n",
       "      <td>₹27,999</td>\n",
       "      <td>https://www.flipkart.com/google-pixel-6a-charc...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Google</td>\n",
       "      <td>Pixel 6a</td>\n",
       "      <td>Chalk</td>\n",
       "      <td>6 GB</td>\n",
       "      <td>128 GB</td>\n",
       "      <td>12.2MP + 12MP</td>\n",
       "      <td>8MP Front Camera</td>\n",
       "      <td>15.6 cm (6.14 inch)</td>\n",
       "      <td>4410 mAh</td>\n",
       "      <td>₹27,999</td>\n",
       "      <td>https://www.flipkart.com/google-pixel-6a-chalk...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Google</td>\n",
       "      <td>Pixel 3A</td>\n",
       "      <td>Just Black</td>\n",
       "      <td>4 GB</td>\n",
       "      <td>64 GB</td>\n",
       "      <td>12.2MP Rear Camera</td>\n",
       "      <td>-</td>\n",
       "      <td>14.22 cm (5.6 inch)</td>\n",
       "      <td>3000 mAh</td>\n",
       "      <td>₹17,499</td>\n",
       "      <td>https://www.flipkart.com/google-pixel-3a-just-...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Google</td>\n",
       "      <td>Pixel 3</td>\n",
       "      <td>Not Pink</td>\n",
       "      <td>4 GB</td>\n",
       "      <td>128 GB</td>\n",
       "      <td>12.2MP Rear Camera</td>\n",
       "      <td>8MP + 8MP Dual Front Camera</td>\n",
       "      <td>13.97 cm (5.5 inch)</td>\n",
       "      <td>2915 mAh</td>\n",
       "      <td>₹80,000</td>\n",
       "      <td>https://www.flipkart.com/google-pixel-3-not-pi...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Google</td>\n",
       "      <td>Pixel 3A</td>\n",
       "      <td>Purple-ish</td>\n",
       "      <td>4 GB</td>\n",
       "      <td>64 GB</td>\n",
       "      <td>12.2MP Rear Camera</td>\n",
       "      <td>-</td>\n",
       "      <td>14.22 cm (5.6 inch)</td>\n",
       "      <td>3000 mAh</td>\n",
       "      <td>₹17,899</td>\n",
       "      <td>https://www.flipkart.com/google-pixel-3a-purpl...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    Brand Phone name      Colour   RAM Storage(ROM)      Primary Camera  \\\n",
       "0  Google   Pixel 6a    Charcoal  6 GB       128 GB       12.2MP + 12MP   \n",
       "1  Google   Pixel 6a       Chalk  6 GB       128 GB       12.2MP + 12MP   \n",
       "2  Google   Pixel 3A  Just Black  4 GB        64 GB  12.2MP Rear Camera   \n",
       "3  Google    Pixel 3    Not Pink  4 GB       128 GB  12.2MP Rear Camera   \n",
       "4  Google   Pixel 3A  Purple-ish  4 GB        64 GB  12.2MP Rear Camera   \n",
       "\n",
       "              Secondary Camera         Display Size Battery Capacity    Price  \\\n",
       "0             8MP Front Camera  15.6 cm (6.14 inch)         4410 mAh  ₹27,999   \n",
       "1             8MP Front Camera  15.6 cm (6.14 inch)         4410 mAh  ₹27,999   \n",
       "2                            -  14.22 cm (5.6 inch)         3000 mAh  ₹17,499   \n",
       "3  8MP + 8MP Dual Front Camera  13.97 cm (5.5 inch)         2915 mAh  ₹80,000   \n",
       "4                            -  14.22 cm (5.6 inch)         3000 mAh  ₹17,899   \n",
       "\n",
       "                                                 URL  \n",
       "0  https://www.flipkart.com/google-pixel-6a-charc...  \n",
       "1  https://www.flipkart.com/google-pixel-6a-chalk...  \n",
       "2  https://www.flipkart.com/google-pixel-3a-just-...  \n",
       "3  https://www.flipkart.com/google-pixel-3-not-pi...  \n",
       "4  https://www.flipkart.com/google-pixel-3a-purpl...  "
      ]
     },
     "execution_count": 251,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = pd.DataFrame.from_dict(Smartphones)\n",
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 252,
   "id": "ac7c7545",
   "metadata": {},
   "outputs": [],
   "source": [
    "df.to_csv(\"smartphones.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 253,
   "id": "5b9fa0e5",
   "metadata": {},
   "outputs": [],
   "source": [
    "driver.close()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8a7be6db",
   "metadata": {},
   "source": [
    "Q5.Write a program to scrap geospatial coordinates (latitude, longitude) of a city searched on google maps. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "id": "7a4bd636",
   "metadata": {},
   "outputs": [],
   "source": [
    "s=Service(ChromeDriverManager().install())\n",
    "driver = webdriver.Chrome(service=s)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "id": "61843752",
   "metadata": {},
   "outputs": [],
   "source": [
    "url = 'https://www.google.co.in/maps'\n",
    "driver.get(url)\n",
    "time.sleep(2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "id": "2926ad3a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Enter City name that has to be searched : hyderabad\n"
     ]
    }
   ],
   "source": [
    "City = input('Enter City name that has to be searched : ')\n",
    "search_bar = driver.find_element(By.ID,'searchboxinput')\n",
    "search_bar.click()\n",
    "time.sleep(2)\n",
    "search_bar.send_keys(City)\n",
    "search_btn = driver.find_element(By.ID,\"searchbox-searchbutton\")\n",
    "search_btn.click()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "id": "f80c973f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "URL Extracted:  https://www.google.co.in/maps/place/Hyderabad,+Telangana/@17.4120779,78.0783747,10z/data=!3m1!4b1!4m6!3m5!1s0x3bcb99daeaebd2c7:0xae93b78392bafbc2!8m2!3d17.385044!4d78.486671!16zL20vMDljNnc?entry=ttu\n",
      "Latitude = 17.4120779, Longitude = 78.0783747\n"
     ]
    }
   ],
   "source": [
    "try:\n",
    "    url_str = driver.current_url\n",
    "    print(\"URL Extracted: \", url_str)\n",
    "    latitude_longitude = re.findall(r'@(.*)data',url_str)\n",
    "    if len(latitude_longitude):\n",
    "        lat_lng_list = latitude_longitude[0].split(\",\")\n",
    "        if len(lat_lng_list)>=2:\n",
    "            latitude = lat_lng_list[0]\n",
    "            longitude = lat_lng_list[1]\n",
    "        print(\"Latitude = {}, Longitude = {}\".format(latitude, longitude))\n",
    "except Exception as e:\n",
    "        print(\"Error: \", str(e))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "06fdecdd",
   "metadata": {},
   "source": [
    "Q6 : Write a program to scrap all the available details of best gaming laptops from digit.in."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "323243b9",
   "metadata": {},
   "outputs": [],
   "source": [
    "s=Service(ChromeDriverManager().install())\n",
    "driver = webdriver.Chrome(service=s)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "id": "e33181be",
   "metadata": {},
   "outputs": [],
   "source": [
    "url = \"https://www.digit.in/\"\n",
    "driver.get(url)\n",
    "time.sleep(2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "id": "b265120f",
   "metadata": {},
   "outputs": [],
   "source": [
    "best_gam_laptops = driver.find_element(By.XPATH,\"//div[@class='listing_container']//ul//li[9]\").click()\n",
    "time.sleep(3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "id": "1cf7434d",
   "metadata": {},
   "outputs": [],
   "source": [
    "Laptop_Name = []\n",
    "Operating_sys = []\n",
    "Display = []\n",
    "Processor = []\n",
    "Memory = []\n",
    "Weight = []\n",
    "Dimensions = []\n",
    "Graph_proc = []\n",
    "Price = []"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "id": "1272b275",
   "metadata": {},
   "outputs": [],
   "source": [
    "laptop_name = driver.find_elements(By.XPATH,\"//span[@class='datahreflink']/h3\")\n",
    "for name in laptop_name:\n",
    "    Laptop_Name.append(name.text)\n",
    "    \n",
    "\n",
    "try:\n",
    "    op_sys = driver.find_elements(By.XPATH,\"//div[@class='Spcs-details']/table/tbody/tr[4]/td[3]\")\n",
    "    for os in op_sys:\n",
    "        Operating_sys.append(os.text)\n",
    "except NoSuchElementException:\n",
    "    pass\n",
    "\n",
    "\n",
    "try:\n",
    "    display = driver.find_elements(By.XPATH,\"//div[@class='Spcs-details']/table/tbody/tr[3]/td[3]\")\n",
    "    for disp in display:\n",
    "        Display.append(disp.text)\n",
    "except NoSuchElementException:\n",
    "    pass\n",
    "\n",
    "\n",
    "\n",
    "try:\n",
    "    processor = driver.find_elements(By.XPATH,\"//div[@class='Spcs-details']/table/tbody/tr[2]/td[3]\")\n",
    "    for pro in processor:\n",
    "        Processor.append(pro.text)\n",
    "except NoSuchElementException:\n",
    "    pass\n",
    "\n",
    "\n",
    "\n",
    "try:\n",
    "    memory = driver.find_elements(By.XPATH,\"//div[@class='Spcs-details']/table/tbody/tr[5]/td[3]\")\n",
    "    for memo in memory:\n",
    "        Memory.append(memo.text)\n",
    "except NoSuchElementException:\n",
    "    pass\n",
    "\n",
    "\n",
    "try:\n",
    "    weight = driver.find_elements(By.XPATH,\"//div[@class='Spcs-details']/table/tbody/tr[7]/td[3]\")\n",
    "    for wgt in weight:\n",
    "        Weight.append(wgt.text)\n",
    "except NoSuchElementException:\n",
    "    pass\n",
    "\n",
    "try:\n",
    "    graph = driver.find_elements(By.XPATH,\"//div[@class='Spcs-details']/table/tbody/tr[6]/td[3]\")\n",
    "    for gra in graph:\n",
    "        Graph_proc.append(gra.text)\n",
    "except NoSuchElementException:\n",
    "    pass\n",
    "\n",
    "\n",
    "try:\n",
    "    price = driver.find_elements(By.XPATH,\"//div[@class='Spcs-details']/table/tbody/tr[8]/td[3]\")\n",
    "    for pri in price:\n",
    "        Price.append(pri.text.replace('₹ ','Rs'))\n",
    "except NoSuchElementException:\n",
    "    pass"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "id": "f431274d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "7 7 7 7 7 7 7 7\n"
     ]
    }
   ],
   "source": [
    "print(len(Laptop_Name),\n",
    "len(Operating_sys),\n",
    "len(Display),\n",
    "len(Processor),\n",
    "len(Memory),\n",
    "len(Weight), \n",
    "len(Graph_proc),\n",
    "len(Price))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "id": "fac98373",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Laptop Name</th>\n",
       "      <th>Operating System</th>\n",
       "      <th>Display</th>\n",
       "      <th>Processor</th>\n",
       "      <th>Memory</th>\n",
       "      <th>Weight</th>\n",
       "      <th>Graphical Processor</th>\n",
       "      <th>Price</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>HP OMEN 17 (2023)</td>\n",
       "      <td>Windows 11 Home</td>\n",
       "      <td>17.3″ (2560 x 1440) screen, 165 Hz refresh rate</td>\n",
       "      <td>13th Gen Intel Core i7-13700HX 16 core process...</td>\n",
       "      <td>16 GB DDR5GB RAM &amp; 1 TB SSD</td>\n",
       "      <td>397.1 x 262 x 27 mm dimension &amp; 2.78 kg weight</td>\n",
       "      <td>12 GB DDR6 NVIDIA GeForce RTX 4080 Graphics card</td>\n",
       "      <td>Rs269,777</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>MSI Titan GT77 12UHS</td>\n",
       "      <td>Windows 11 Home</td>\n",
       "      <td>17.3″ (3840 x 2160) screen, 120 Hz refresh rate</td>\n",
       "      <td>12th Gen Intel Core i9-12900HX 16 core process...</td>\n",
       "      <td>64 GB DDR5GB RAM &amp; 2 TB SSD</td>\n",
       "      <td>397 x 330 x 23 mm dimension &amp; 3.3 kg weight</td>\n",
       "      <td>16 GB DDR6 NVIDIA GeForce RTX 3080Ti Graphics ...</td>\n",
       "      <td>Rs499,990</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Lenovo Legion 5i Pro</td>\n",
       "      <td>Windows 11 Home</td>\n",
       "      <td>16″ (2560 x 1600) screen</td>\n",
       "      <td>12th Gen Intel Core i7-12700H 14 core processo...</td>\n",
       "      <td>32 GB DDR5GB RAM &amp; 1 TB SSD</td>\n",
       "      <td>359.9 x 264.4 x 19.9 mm dimension &amp; 3.6 kg weight</td>\n",
       "      <td>NVIDIA GeForce RTX 3070 Ti Graphics card</td>\n",
       "      <td>Rs213,900</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>ASUS ROG Strix Scar 18 2023</td>\n",
       "      <td>Windows 11 Home</td>\n",
       "      <td>18″ (1920 x 1200) screen, 165 Hz refresh rate</td>\n",
       "      <td>13th Gen Intel Core i9-13980HX 24 core process...</td>\n",
       "      <td>32 GB DDR5GB RAM &amp; 1 TB SSD</td>\n",
       "      <td>294 x 399 x 23 mm dimension &amp; 3.1 kg weight</td>\n",
       "      <td>12 GB DDR6 NVIDIA GeForce RTX 4080 Graphics card</td>\n",
       "      <td>Rs279,990</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Acer Predator Helios Neo 16</td>\n",
       "      <td>Windows 11 Home</td>\n",
       "      <td>16″ (2560 x 1600) screen, 165 Hz refresh rate</td>\n",
       "      <td>13th Gen Intel Core i7-13700HX processor</td>\n",
       "      <td>16 GB DDR5GB RAM &amp; 1 TB SSD</td>\n",
       "      <td>360 x 279 x 28 mm dimension &amp; 2.6 kg weight</td>\n",
       "      <td>8 GB DDR6 NVIDIA GeForce RTX 4060 Graphics card</td>\n",
       "      <td>Rs149,990</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>ASUS ROG Zephyrus G14</td>\n",
       "      <td>Windows 11 Home</td>\n",
       "      <td>14″ (1920 x 1200) screen, 144 Hz refresh rate</td>\n",
       "      <td>AMD Ryzen 9-6900HS 8 core processor with 4.9 G...</td>\n",
       "      <td>16 GB DDR5GB RAM &amp; 1 TB SSD</td>\n",
       "      <td>312 x 227 x 19 mm dimension &amp; 1.65 kg weight</td>\n",
       "      <td>8 GB DDR6 AMD Radeon RX 6700S Graphics card</td>\n",
       "      <td>Rs156,990</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>MSI Cyborg 15</td>\n",
       "      <td>Windows 11 Home</td>\n",
       "      <td>15.6″ (1920 x 1080) screen, 144 Hz refresh rate</td>\n",
       "      <td>12th Gen Intel Core i7-12650H 10 core processo...</td>\n",
       "      <td>16 GB DDR5GB RAM &amp; 1 TB SSD</td>\n",
       "      <td>&amp; 1.98 kg weight</td>\n",
       "      <td>8 GB DDR6 NVIDIA GeForce RTX 4060 Graphics card</td>\n",
       "      <td>Rs130,990</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                   Laptop Name Operating System  \\\n",
       "0            HP OMEN 17 (2023)  Windows 11 Home   \n",
       "1         MSI Titan GT77 12UHS  Windows 11 Home   \n",
       "2         Lenovo Legion 5i Pro  Windows 11 Home   \n",
       "3  ASUS ROG Strix Scar 18 2023  Windows 11 Home   \n",
       "4  Acer Predator Helios Neo 16  Windows 11 Home   \n",
       "5        ASUS ROG Zephyrus G14  Windows 11 Home   \n",
       "6                MSI Cyborg 15  Windows 11 Home   \n",
       "\n",
       "                                           Display  \\\n",
       "0  17.3″ (2560 x 1440) screen, 165 Hz refresh rate   \n",
       "1  17.3″ (3840 x 2160) screen, 120 Hz refresh rate   \n",
       "2                         16″ (2560 x 1600) screen   \n",
       "3    18″ (1920 x 1200) screen, 165 Hz refresh rate   \n",
       "4    16″ (2560 x 1600) screen, 165 Hz refresh rate   \n",
       "5    14″ (1920 x 1200) screen, 144 Hz refresh rate   \n",
       "6  15.6″ (1920 x 1080) screen, 144 Hz refresh rate   \n",
       "\n",
       "                                           Processor  \\\n",
       "0  13th Gen Intel Core i7-13700HX 16 core process...   \n",
       "1  12th Gen Intel Core i9-12900HX 16 core process...   \n",
       "2  12th Gen Intel Core i7-12700H 14 core processo...   \n",
       "3  13th Gen Intel Core i9-13980HX 24 core process...   \n",
       "4           13th Gen Intel Core i7-13700HX processor   \n",
       "5  AMD Ryzen 9-6900HS 8 core processor with 4.9 G...   \n",
       "6  12th Gen Intel Core i7-12650H 10 core processo...   \n",
       "\n",
       "                        Memory  \\\n",
       "0  16 GB DDR5GB RAM & 1 TB SSD   \n",
       "1  64 GB DDR5GB RAM & 2 TB SSD   \n",
       "2  32 GB DDR5GB RAM & 1 TB SSD   \n",
       "3  32 GB DDR5GB RAM & 1 TB SSD   \n",
       "4  16 GB DDR5GB RAM & 1 TB SSD   \n",
       "5  16 GB DDR5GB RAM & 1 TB SSD   \n",
       "6  16 GB DDR5GB RAM & 1 TB SSD   \n",
       "\n",
       "                                              Weight  \\\n",
       "0     397.1 x 262 x 27 mm dimension & 2.78 kg weight   \n",
       "1        397 x 330 x 23 mm dimension & 3.3 kg weight   \n",
       "2  359.9 x 264.4 x 19.9 mm dimension & 3.6 kg weight   \n",
       "3        294 x 399 x 23 mm dimension & 3.1 kg weight   \n",
       "4        360 x 279 x 28 mm dimension & 2.6 kg weight   \n",
       "5       312 x 227 x 19 mm dimension & 1.65 kg weight   \n",
       "6                                   & 1.98 kg weight   \n",
       "\n",
       "                                 Graphical Processor      Price  \n",
       "0   12 GB DDR6 NVIDIA GeForce RTX 4080 Graphics card  Rs269,777  \n",
       "1  16 GB DDR6 NVIDIA GeForce RTX 3080Ti Graphics ...  Rs499,990  \n",
       "2           NVIDIA GeForce RTX 3070 Ti Graphics card  Rs213,900  \n",
       "3   12 GB DDR6 NVIDIA GeForce RTX 4080 Graphics card  Rs279,990  \n",
       "4    8 GB DDR6 NVIDIA GeForce RTX 4060 Graphics card  Rs149,990  \n",
       "5        8 GB DDR6 AMD Radeon RX 6700S Graphics card  Rs156,990  \n",
       "6    8 GB DDR6 NVIDIA GeForce RTX 4060 Graphics card  Rs130,990  "
      ]
     },
     "execution_count": 61,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "Gaming_Laptop=pd.DataFrame({})\n",
    "Gaming_Laptop['Laptop Name'] = Laptop_Name\n",
    "Gaming_Laptop['Operating System'] =Operating_sys\n",
    "Gaming_Laptop['Display'] = Display\n",
    "Gaming_Laptop['Processor'] = Processor\n",
    "Gaming_Laptop['Memory'] = Memory\n",
    "Gaming_Laptop['Weight'] = Weight\n",
    "Gaming_Laptop['Graphical Processor'] = Graph_proc\n",
    "Gaming_Laptop['Price'] = Price\n",
    "Gaming_Laptop"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f718b7da",
   "metadata": {},
   "source": [
    "Q7.Write a python program to scrape the details for all billionaires from www.forbes.com. Details to be scrapped: \n",
    "“Rank”, “Name”, “Net worth”, “Age”, “Citizenship”, “Source”, “Industry”. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "a53cd253",
   "metadata": {},
   "outputs": [],
   "source": [
    "from webdriver_manager.chrome import ChromeDriverManager\n",
    "\n",
    "driver = webdriver.Chrome(service=Service(ChromeDriverManager().install()))\n",
    "\n",
    "url = \"https://www.forbes.com/?sh=69e6b8c92254\"\n",
    "driver.get(url)\n",
    "time.sleep(3)\n",
    "\n",
    "#clicking on the explore button\n",
    "button = driver.find_element(By.XPATH,\"//div[@class='_69hVhdY4']\")\n",
    "button.click()\n",
    "time.sleep(1)\n",
    "\n",
    "#select billionaire  \n",
    "bill = driver.find_element(By.XPATH,\"/html/body/div[1]/header/nav/div[1]/div[1]/div/div[2]/ul/li[2]\")\n",
    "bill.click()\n",
    "time.sleep(1)\n",
    "\n",
    "world_bill= driver.find_element(By.XPATH,\"/html/body/div[1]/div[2]/main/div/section/div[2]/div/div/div[1]/div/div[1]/div/div/a/h2\")\n",
    "world_bill.click()\n",
    "time.sleep(1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "539beb78",
   "metadata": {},
   "outputs": [],
   "source": [
    "Rank = []\n",
    "Person_Name = []\n",
    "Net_worth  = []\n",
    "Age = []\n",
    "Citizenship = []\n",
    "Source = []\n",
    "Industry = []\n",
    "\n",
    "while(True):\n",
    "    \n",
    "     # scraping the data of rank of the billionaires\n",
    "    rank_tag = driver.find_elements(By.XPATH,\"//div[@class='Table_rank___YBhk Table_dataCell__2QCve']\")\n",
    "    for i in rank_tag:\n",
    "        rank_tag=i.text\n",
    "        Rank.append(rank_tag)\n",
    "        time.sleep(1)\n",
    "        \n",
    " \n",
    "    # scraping the data  of names of the billionaires\n",
    "    name_tag = driver.find_elements(By.XPATH,\"//div[2][@class='TableRow_cell__db-hv Table_cell__houv9']\")\n",
    "    for i in name_tag:\n",
    "        name_tag=i.text\n",
    "        Person_Name.append(name_tag)\n",
    "        time.sleep(1)\n",
    "    \n",
    "    \n",
    "    # scraping the data of age of the billionaires\n",
    "    age_tag = driver.find_elements(By.XPATH,\"//div[4][@class='TableRow_cell__db-hv Table_cell__houv9']\")\n",
    "    for i in age_tag:\n",
    "        age_tag=i.text\n",
    "        Age.append(age_tag)\n",
    "        time.sleep(1)\n",
    "    \n",
    "    \n",
    "    # scraping the data of citizenship of the billionaires\n",
    "    cit_tag = driver.find_elements(By.XPATH,\"//div[5][@class='TableRow_cell__db-hv Table_cell__houv9']\") \n",
    "    for i in cit_tag:\n",
    "        cit_tag=i.text\n",
    "        Citizenship.append(cit_tag)\n",
    "        time.sleep(1)\n",
    "     \n",
    "    \n",
    "    # scraping the data of source of income of the billionaires\n",
    "    sour_tag = driver.find_elements(By.XPATH,\"//div[6][@class='TableRow_cell__db-hv Table_cell__houv9']\")\n",
    "    for i in sour_tag:\n",
    "        sour_tag=i.text\n",
    "        Source.append(sour_tag)\n",
    "        time.sleep(1)\n",
    "    \n",
    "    \n",
    "    # scraping data of industry of the billionaires\n",
    "    ind_tag = driver.find_elements(By.XPATH,\"//div[7][@class='TableRow_cell__db-hv Table_cell__houv9']\")\n",
    "    for i in ind_tag:\n",
    "        ind_tag=i.text\n",
    "        Industry.append(ind_tag)\n",
    "        time.sleep(1)\n",
    "    \n",
    "    \n",
    "    # scraping data of net_worth of billionaires\n",
    "    net_tag = driver.find_elements(By.XPATH,\"//div[3][@class='TableRow_cell__db-hv Table_cell__houv9']\")\n",
    "    for i in net_tag:\n",
    "        net_tag=i.text\n",
    "        Net_worth .append(net_tag)\n",
    "        time.sleep(1)\n",
    "\n",
    "    try:\n",
    "        next_button = driver.find_element(By.XPATH,\"//div[@class='Pagination_pagination__V7MBu']/button[2]\")\n",
    "        next_button.click()\n",
    "    except:\n",
    "        break\n",
    "        \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "b31674b6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2640 2640 2640 2640 2640 2640 2640\n"
     ]
    }
   ],
   "source": [
    "print(len(Rank),len(Person_Name),len(Age),len(Citizenship),len(Source),len(Industry),len(Net_worth))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "95808470",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "df=pd.DataFrame({'Rank':Rank,\n",
    "                 'Person Name':Person_Name,\n",
    "                 'Net Worth': Net_worth,\n",
    "                 'Age':Age,\n",
    "                 'Country':Citizenship,\n",
    "                 'Source':Source,\n",
    "                 'Industry':Industry})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "c30e6da6",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Rank</th>\n",
       "      <th>Person Name</th>\n",
       "      <th>Net Worth</th>\n",
       "      <th>Age</th>\n",
       "      <th>Country</th>\n",
       "      <th>Source</th>\n",
       "      <th>Industry</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>Bernard Arnault &amp; family</td>\n",
       "      <td>$211 B</td>\n",
       "      <td>74</td>\n",
       "      <td>France</td>\n",
       "      <td>LVMH</td>\n",
       "      <td>Fashion &amp; Retail</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2</td>\n",
       "      <td>Elon Musk</td>\n",
       "      <td>$180 B</td>\n",
       "      <td>51</td>\n",
       "      <td>United States</td>\n",
       "      <td>Tesla, SpaceX</td>\n",
       "      <td>Automotive</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3</td>\n",
       "      <td>Jeff Bezos</td>\n",
       "      <td>$114 B</td>\n",
       "      <td>59</td>\n",
       "      <td>United States</td>\n",
       "      <td>Amazon</td>\n",
       "      <td>Technology</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4</td>\n",
       "      <td>Larry Ellison</td>\n",
       "      <td>$107 B</td>\n",
       "      <td>78</td>\n",
       "      <td>United States</td>\n",
       "      <td>Oracle</td>\n",
       "      <td>Technology</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>5</td>\n",
       "      <td>Warren Buffett</td>\n",
       "      <td>$106 B</td>\n",
       "      <td>92</td>\n",
       "      <td>United States</td>\n",
       "      <td>Berkshire Hathaway</td>\n",
       "      <td>Finance &amp; Investments</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2635</th>\n",
       "      <td>2540</td>\n",
       "      <td>Yu Rong</td>\n",
       "      <td>$1 B</td>\n",
       "      <td>51</td>\n",
       "      <td>China</td>\n",
       "      <td>Health clinics</td>\n",
       "      <td>Healthcare</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2636</th>\n",
       "      <td>2540</td>\n",
       "      <td>Richard Yuengling, Jr.</td>\n",
       "      <td>$1 B</td>\n",
       "      <td>80</td>\n",
       "      <td>United States</td>\n",
       "      <td>Beer</td>\n",
       "      <td>Food &amp; Beverage</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2637</th>\n",
       "      <td>2540</td>\n",
       "      <td>Zhang Gongyun</td>\n",
       "      <td>$1 B</td>\n",
       "      <td>60</td>\n",
       "      <td>China</td>\n",
       "      <td>Tyre manufacturing machinery</td>\n",
       "      <td>Manufacturing</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2638</th>\n",
       "      <td>2540</td>\n",
       "      <td>Zhang Guiping &amp; family</td>\n",
       "      <td>$1 B</td>\n",
       "      <td>71</td>\n",
       "      <td>China</td>\n",
       "      <td>Real estate</td>\n",
       "      <td>Real Estate</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2639</th>\n",
       "      <td>2540</td>\n",
       "      <td>Inigo Zobel</td>\n",
       "      <td>$1 B</td>\n",
       "      <td>66</td>\n",
       "      <td>Philippines</td>\n",
       "      <td>Diversified</td>\n",
       "      <td>Diversified</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>2640 rows × 7 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "      Rank               Person Name Net Worth Age        Country  \\\n",
       "0        1  Bernard Arnault & family    $211 B  74         France   \n",
       "1        2                 Elon Musk    $180 B  51  United States   \n",
       "2        3                Jeff Bezos    $114 B  59  United States   \n",
       "3        4             Larry Ellison    $107 B  78  United States   \n",
       "4        5            Warren Buffett    $106 B  92  United States   \n",
       "...    ...                       ...       ...  ..            ...   \n",
       "2635  2540                   Yu Rong      $1 B  51          China   \n",
       "2636  2540    Richard Yuengling, Jr.      $1 B  80  United States   \n",
       "2637  2540             Zhang Gongyun      $1 B  60          China   \n",
       "2638  2540    Zhang Guiping & family      $1 B  71          China   \n",
       "2639  2540               Inigo Zobel      $1 B  66    Philippines   \n",
       "\n",
       "                            Source               Industry  \n",
       "0                             LVMH       Fashion & Retail  \n",
       "1                    Tesla, SpaceX             Automotive  \n",
       "2                           Amazon             Technology  \n",
       "3                           Oracle             Technology  \n",
       "4               Berkshire Hathaway  Finance & Investments  \n",
       "...                            ...                    ...  \n",
       "2635                Health clinics             Healthcare  \n",
       "2636                          Beer        Food & Beverage  \n",
       "2637  Tyre manufacturing machinery          Manufacturing  \n",
       "2638                   Real estate            Real Estate  \n",
       "2639                   Diversified            Diversified  \n",
       "\n",
       "[2640 rows x 7 columns]"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "052bbc2d",
   "metadata": {},
   "outputs": [],
   "source": [
    "df.to_csv(\"Billonaires.csv\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8ae20066",
   "metadata": {},
   "source": [
    "Q8 : Write a program to extract at least 500 Comments, Comment upvote and time when comment was posted from any YouTube Video. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "id": "ce2e6856",
   "metadata": {},
   "outputs": [],
   "source": [
    "from webdriver_manager.chrome import ChromeDriverManager\n",
    "\n",
    "driver = webdriver.Chrome(service=Service(ChromeDriverManager().install()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "867813ae",
   "metadata": {},
   "outputs": [],
   "source": [
    "url = \"https://www.youtube.com/\"\n",
    "search_item = [\"natu natu song\"]\n",
    "for item in search_item:\n",
    "    driver.get(url)  \n",
    "    time.sleep(5)\n",
    "    \n",
    "    # Finding webelement for search_bar\n",
    "    search_bar = driver.find_element(By.XPATH,\"//div[@class='ytd-searchbox-spt']/input\")\n",
    "    \n",
    "    # Sending keys to get the keyword for search bar\n",
    "    search_bar.send_keys(search_item)\n",
    "    search_btn = driver.find_element(By.ID,\"search-icon-legacy\")\n",
    "    search_btn.click()\n",
    "    time.sleep(2)\n",
    "    # Clicking on search button\n",
    "    search_button =driver.find_element(By.XPATH,\"//yt-formatted-string[@class='style-scope ytd-video-renderer']\").click()\n",
    "    \n",
    "    # Scrolling down the webpage to get some more images\n",
    "    for _ in range(1000):\n",
    "        driver.execute_script(\"window.scrollBy(0,1000)\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "0ec96da9",
   "metadata": {},
   "outputs": [],
   "source": [
    "comments = []\n",
    "comment_time = []\n",
    "Time = []\n",
    "Likes = []\n",
    "No_of_Likes = []\n",
    "\n",
    "# scrape comments\n",
    "cm = driver.find_elements(By.ID,\"content-text\")\n",
    "for i in cm:\n",
    "    if i.text is None:\n",
    "        comments.append(\"--\")\n",
    "    else:\n",
    "        comments.append(i.text)\n",
    "time.sleep(4)\n",
    "\n",
    "\n",
    "# scrape time when comment was posted\n",
    "tm = driver.find_elements(By.XPATH,\"//a[contains(text(),'ago')]\")\n",
    "for i in tm:\n",
    "    Time.append(i.text)\n",
    "    \n",
    "for i in range(0,len(Time)):\n",
    "    comment_time.append(Time[i])\n",
    "time.sleep(4)\n",
    "\n",
    "\n",
    "# scrape the comment likes\n",
    "like = driver.find_elements(By.XPATH,\"//span[@class='style-scope ytd-comment-action-buttons-renderer']\")\n",
    "for i in like:\n",
    "    Likes.append(i.text)\n",
    "    \n",
    "for i in range(1,len(Likes),2):\n",
    "    No_of_Likes.append(Likes[i])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "id": "7eeb6dc8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "720 720 720\n"
     ]
    }
   ],
   "source": [
    "print(len(comments),len(comment_time),len(No_of_Likes))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "id": "ec3eb1e9",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Comment</th>\n",
       "      <th>Comment Time</th>\n",
       "      <th>Comment Upvotes</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Oscar winning moment. Proud moment for every i...</td>\n",
       "      <td>2 months ago (edited)</td>\n",
       "      <td>160</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>FULLY deserved the Oscar , as an Indian I’m ju...</td>\n",
       "      <td>2 months ago</td>\n",
       "      <td>200</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>The love he has for his friend always gets me....</td>\n",
       "      <td>4 weeks ago</td>\n",
       "      <td>240</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>This song is so ! I can't stop singing it!  Th...</td>\n",
       "      <td>2 weeks ago</td>\n",
       "      <td>13</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Proud moment for India this song won Oscar awa...</td>\n",
       "      <td>1 month ago</td>\n",
       "      <td>76</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>495</th>\n",
       "      <td>Very good</td>\n",
       "      <td>1 month ago</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>496</th>\n",
       "      <td>Seeing again after 1 year</td>\n",
       "      <td>4 weeks ago</td>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>497</th>\n",
       "      <td>Lovely</td>\n",
       "      <td>5 days ago</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>498</th>\n",
       "      <td>I rewatched this scene so many times on Netfli...</td>\n",
       "      <td>9 months ago</td>\n",
       "      <td>422</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>499</th>\n",
       "      <td>I love this song</td>\n",
       "      <td>2 months ago</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>500 rows × 3 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                               Comment           Comment Time  \\\n",
       "0    Oscar winning moment. Proud moment for every i...  2 months ago (edited)   \n",
       "1    FULLY deserved the Oscar , as an Indian I’m ju...           2 months ago   \n",
       "2    The love he has for his friend always gets me....            4 weeks ago   \n",
       "3    This song is so ! I can't stop singing it!  Th...            2 weeks ago   \n",
       "4    Proud moment for India this song won Oscar awa...            1 month ago   \n",
       "..                                                 ...                    ...   \n",
       "495                                         Very good             1 month ago   \n",
       "496                          Seeing again after 1 year            4 weeks ago   \n",
       "497                                            Lovely              5 days ago   \n",
       "498  I rewatched this scene so many times on Netfli...           9 months ago   \n",
       "499                                   I love this song           2 months ago   \n",
       "\n",
       "    Comment Upvotes  \n",
       "0               160  \n",
       "1               200  \n",
       "2               240  \n",
       "3                13  \n",
       "4                76  \n",
       "..              ...  \n",
       "495               1  \n",
       "496                  \n",
       "497               1  \n",
       "498             422  \n",
       "499               2  \n",
       "\n",
       "[500 rows x 3 columns]"
      ]
     },
     "execution_count": 49,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Youtube = pd.DataFrame({})\n",
    "Youtube['Comment'] = comments[:500]\n",
    "Youtube['Comment Time'] = comment_time[:500]\n",
    "Youtube['Comment Upvotes'] = No_of_Likes[:500]\n",
    "Youtube"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "id": "3ad654a3",
   "metadata": {},
   "outputs": [],
   "source": [
    "Youtube.to_csv(\"Youtube Natu natu Comments.csv\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3038e6e7",
   "metadata": {},
   "source": [
    "Q9. Write a python program to scrape a data for all available Hostels from https://www.hostelworld.com/ in \n",
    "“London” location. You have to scrape hostel name, distance from city centre, ratings, total reviews, overall \n",
    "reviews, privates from price, dorms from price, facilities and property description. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "c83df9ac",
   "metadata": {},
   "outputs": [],
   "source": [
    "from webdriver_manager.chrome import ChromeDriverManager\n",
    "\n",
    "driver = webdriver.Chrome(service=Service(ChromeDriverManager().install()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "72d102b6",
   "metadata": {},
   "outputs": [],
   "source": [
    "url = \"https://www.hostelworld.com/\"\n",
    "driver.get(url)\n",
    "time.sleep(3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "a8d828bc",
   "metadata": {},
   "outputs": [],
   "source": [
    "try:\n",
    "        search_loc = driver.find_element(By.ID,'location-text-input-field')\n",
    "        search_loc.send_keys(\"London\")\n",
    "        \n",
    "except NoSuchElementException as e:\n",
    "        time.sleep(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "3be5556b",
   "metadata": {},
   "outputs": [],
   "source": [
    "try:\n",
    "    london_loc = driver.find_element(By.ID,'search-input-field')\n",
    "    london_loc.send_keys(\"London\")\n",
    "except NoSuchElementException as e:\n",
    "      time.sleep(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "450c924f",
   "metadata": {},
   "outputs": [],
   "source": [
    "try:\n",
    "    london = driver.find_element(By.XPATH,'//html/body/div[3]/div/div/div[2]/div[2]/div/div/div[4]/div/div[2]/div/div[1]/div/div/ul/li[2]/div')\n",
    "    london.click()\n",
    "\n",
    "except NoSuchElementException as e:\n",
    "    time.sleep(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "39d926ce",
   "metadata": {},
   "outputs": [],
   "source": [
    "try:\n",
    "    letsgo = driver.find_element(By.XPATH,'//div[@class=\"search-button\"]/button')\n",
    "# write Lonodn in search bar\n",
    "    letsgo.click()\n",
    "except ElementClickInterceptedException  as e:\n",
    "      time.sleep(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "fc9ba0ca",
   "metadata": {},
   "outputs": [],
   "source": [
    "hostel_name = []\n",
    "distance = []\n",
    "pvt_prices = []\n",
    "dorms_price = []\n",
    "rating = []\n",
    "reviews = []\n",
    "over_all = []\n",
    "facilities = []\n",
    "description = []\n",
    "product_url= []"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "id": "cd95af00",
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in driver.find_elements(By.XPATH,\"//div[@class = 'pagination-item pagination-current' or @class='pagination-item']\"):\n",
    "    \n",
    "    time.sleep(4)\n",
    "    #fetching hostel name\n",
    "    #for i in driver.find_elements(By.XPATH,\"//div[@class='property']\"):\n",
    "    try:\n",
    "            name = driver.find_elements(By.XPATH,\"//h2[@class='title title-6']\")\n",
    "            for i in name:\n",
    "                hostel_name.append(i.text)\n",
    "    except NoSuchElementException:\n",
    "               hostel_name.append('-')\n",
    "    #fetching distance from city centre\n",
    "    \n",
    "    try:\n",
    "            dist = driver.find_elements(By.XPATH,\"//div[@class='subtitle body-3']/a/span[1]\")\n",
    "            for i in dist:\n",
    "                distance.append(i.text)\n",
    "    except NoSuchElementException:\n",
    "               distance.append('-')\n",
    "        \n",
    "            #fetching facilities\n",
    "    try:\n",
    "            fac1 = driver.find_elements(By.XPATH,\"//div[@class='has-wifi']\")\n",
    "            fac2 = driver.find_elements(By.XPATH,\"//div[@class='has-sanitation']\")\n",
    "            for i in fac1:\n",
    "                for j in fac2:\n",
    "                    facilities.append(i.text +', '+ j.text )\n",
    "    except NoSuchElementException:\n",
    "                   facilities.append('-')\n",
    "                \n",
    "\n",
    "    for i in driver.find_elements(By.XPATH,\"//div[@class='prices-col']\"):\n",
    "    #fetch privates from price\n",
    "        try:\n",
    "            pvt_price = driver.find_element(By.XPATH,\"//div[1][@class='prices-col']\")\n",
    "            pvt_prices.append(pvt_price.text)\n",
    "        except NoSuchElementException:\n",
    "            pvt_prices.append('-')\n",
    "            \n",
    "    #fetching dorms from price\n",
    "    \n",
    "        try:\n",
    "            dorms = driver.find_element(By.XPATH,\"//div[2][@class='prices-col']\")\n",
    "            dorms_price.append(dorms.text)\n",
    "        except NoSuchElementException:\n",
    "            dorms_price.append('-')            \n",
    "    \n",
    "   \n",
    "   \n",
    "    #lets fetch url of each hostel\n",
    "    p_url = driver.find_elements(By.XPATH,\"//div[@class='prices-col']/a[2]\")\n",
    "    for i in p_url:\n",
    "        product_url.append(i.get_attribute('href'))\n",
    "\n",
    "    for i in product_url:\n",
    "        driver.get(i)\n",
    "        time.sleep(3)\n",
    "    #lets click on show more button for description\n",
    "        try:\n",
    "            driver.find_element(By.XPATH,\"//button[@class='button primary small full-width']\").click()\n",
    "            time.sleep(3)\n",
    "        except ElementClickInterceptedException as e1:\n",
    "               time.sleep(3)\n",
    "        except NoSuchElementException as e2:\n",
    "             pass\n",
    "   \n",
    "     #fetching ratings\n",
    "        try:\n",
    "            rat = driver.find_element(By.XPATH,\"//div[@class='score orange big' or @class='score gray big']\")\n",
    "            rating.append(rat.text)\n",
    "        except NoSuchElementException:\n",
    "            rating.append('-')\n",
    "    #fetching total reviews\n",
    "        \n",
    "        try:\n",
    "            rws = driver.find_element(By.XPATH,\"//div[@class='reviews']\")\n",
    "            reviews.append(rws.text.replace('Total Reviews',''))\n",
    "        except NoSuchElementException:\n",
    "               reviews.append('-')\n",
    "        #fetch overall review\n",
    "        try:\n",
    "            overall_rw = driver.find_element(By.XPATH,\"//div[@class='keyword']/span\")\n",
    "            over_all.append(overall_rw.text)\n",
    "        except NoSuchElementException:\n",
    "            over_all.append('-') \n",
    "\n",
    "\n",
    "\n",
    "    #fetch property description \n",
    "    try:\n",
    "        disc = driver.find_element(By.XPATH,\"//div[@class='description-container']/div/div[2]\")\n",
    "        description.append(disc.text)\n",
    "    except NoSuchElementException:\n",
    "           over_all.append('-')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "id": "7407e94f",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.DataFrame({})\n",
    "df['Hostel_Name'] = hostel_name\n",
    "df['Distance fron city centre'] = distance\n",
    "df['Ratings'] = rating[:30]\n",
    "df['Total_reviews'] = reviews[:30]\n",
    "df['Overall Reviews'] = over_all[:30]\n",
    "df['Privates from price'] = pvt_prices\n",
    "df['Dorms from price'] = dorms_price\n",
    "df['Facilities'] = facilities[:30]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "id": "5f02c531",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Hostel_Name</th>\n",
       "      <th>Distance fron city centre</th>\n",
       "      <th>Ratings</th>\n",
       "      <th>Total_reviews</th>\n",
       "      <th>Overall Reviews</th>\n",
       "      <th>Privates from price</th>\n",
       "      <th>Dorms from price</th>\n",
       "      <th>Facilities</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Wombat's City Hostel London</td>\n",
       "      <td>Hostel - 3.6km from city centre</td>\n",
       "      <td>9.0</td>\n",
       "      <td>14896</td>\n",
       "      <td>Superb</td>\n",
       "      <td>-</td>\n",
       "      <td>-</td>\n",
       "      <td>Free WiFi, Follows Covid-19 sanitation guidance</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>St Christopher's Village</td>\n",
       "      <td>Hostel - 1.8km from city centre</td>\n",
       "      <td>7.9</td>\n",
       "      <td>12155</td>\n",
       "      <td>Very Good</td>\n",
       "      <td>-</td>\n",
       "      <td>-</td>\n",
       "      <td>Free WiFi, Follows Covid-19 sanitation guidance</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Urbany Hostel London</td>\n",
       "      <td>Hostel - 5.4km from city centre</td>\n",
       "      <td>9.4</td>\n",
       "      <td>780</td>\n",
       "      <td>Superb</td>\n",
       "      <td>-</td>\n",
       "      <td>-</td>\n",
       "      <td>Free WiFi, Follows Covid-19 sanitation guidance</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>NX London Hostel</td>\n",
       "      <td>Hostel - 6.1km from city centre</td>\n",
       "      <td>8.3</td>\n",
       "      <td>1885</td>\n",
       "      <td>Fabulous</td>\n",
       "      <td>-</td>\n",
       "      <td>-</td>\n",
       "      <td>Free WiFi, Follows Covid-19 sanitation guidance</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Generator London</td>\n",
       "      <td>Hostel - 3km from city centre</td>\n",
       "      <td>7.5</td>\n",
       "      <td>7500</td>\n",
       "      <td>Very Good</td>\n",
       "      <td>-</td>\n",
       "      <td>-</td>\n",
       "      <td>Free WiFi, Follows Covid-19 sanitation guidance</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>Safestay London Elephant &amp; Castle</td>\n",
       "      <td>Hostel - 1.7km from city centre</td>\n",
       "      <td>7.5</td>\n",
       "      <td>4957</td>\n",
       "      <td>Very Good</td>\n",
       "      <td>-</td>\n",
       "      <td>-</td>\n",
       "      <td>Free WiFi, Follows Covid-19 sanitation guidance</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>Phoenix Hostel</td>\n",
       "      <td>Hostel - 4.2km from city centre</td>\n",
       "      <td>7.6</td>\n",
       "      <td>4126</td>\n",
       "      <td>Very Good</td>\n",
       "      <td>-</td>\n",
       "      <td>-</td>\n",
       "      <td>Free WiFi, Follows Covid-19 sanitation guidance</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>Safestay London Kensington Holland Park</td>\n",
       "      <td>Hostel - 5.8km from city centre</td>\n",
       "      <td>7.1</td>\n",
       "      <td>1528</td>\n",
       "      <td>Very Good</td>\n",
       "      <td>-</td>\n",
       "      <td>-</td>\n",
       "      <td>Free WiFi, Follows Covid-19 sanitation guidance</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>No.8 Seven Sisters</td>\n",
       "      <td>Hostel - 9km from city centre</td>\n",
       "      <td>5.7</td>\n",
       "      <td>4010</td>\n",
       "      <td>Rating</td>\n",
       "      <td>-</td>\n",
       "      <td>-</td>\n",
       "      <td>Free WiFi, Follows Covid-19 sanitation guidance</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>Queen Elizabeth Chelsea</td>\n",
       "      <td>Hostel - 5.7km from city centre</td>\n",
       "      <td>7.4</td>\n",
       "      <td>3480</td>\n",
       "      <td>Very Good</td>\n",
       "      <td>-</td>\n",
       "      <td>-</td>\n",
       "      <td>Free WiFi, Follows Covid-19 sanitation guidance</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>St Christopher's Inn - London Bridge</td>\n",
       "      <td>Hostel - 1.8km from city centre</td>\n",
       "      <td>8.0</td>\n",
       "      <td>3506</td>\n",
       "      <td>Fabulous</td>\n",
       "      <td>-</td>\n",
       "      <td>-</td>\n",
       "      <td>Free WiFi, Follows Covid-19 sanitation guidance</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>St Christopher's Hammersmith</td>\n",
       "      <td>Hostel - 7.5km from city centre</td>\n",
       "      <td>7.7</td>\n",
       "      <td>4243</td>\n",
       "      <td>Very Good</td>\n",
       "      <td>-</td>\n",
       "      <td>-</td>\n",
       "      <td>Free WiFi, Follows Covid-19 sanitation guidance</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>International Students House</td>\n",
       "      <td>Hostel - 3.3km from city centre</td>\n",
       "      <td>9.3</td>\n",
       "      <td>1035</td>\n",
       "      <td>Superb</td>\n",
       "      <td>-</td>\n",
       "      <td>-</td>\n",
       "      <td>Free WiFi, Follows Covid-19 sanitation guidance</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>St Christopher's Camden</td>\n",
       "      <td>Hostel - 4.3km from city centre</td>\n",
       "      <td>7.0</td>\n",
       "      <td>4035</td>\n",
       "      <td>Very Good</td>\n",
       "      <td>-</td>\n",
       "      <td>-</td>\n",
       "      <td>Free WiFi, Follows Covid-19 sanitation guidance</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>St Christopher's Greenwich</td>\n",
       "      <td>Hostel - 7.6km from city centre</td>\n",
       "      <td>7.5</td>\n",
       "      <td>3350</td>\n",
       "      <td>Very Good</td>\n",
       "      <td>-</td>\n",
       "      <td>-</td>\n",
       "      <td>Free WiFi, Follows Covid-19 sanitation guidance</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>Bell House Hostel</td>\n",
       "      <td>Hostel - 4.2km from city centre</td>\n",
       "      <td>7.6</td>\n",
       "      <td>60</td>\n",
       "      <td>Very Good</td>\n",
       "      <td>-</td>\n",
       "      <td>-</td>\n",
       "      <td>Free WiFi, Follows Covid-19 sanitation guidance</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>Saint James Backpackers</td>\n",
       "      <td>Hostel - 5.5km from city centre</td>\n",
       "      <td>7.5</td>\n",
       "      <td>1884</td>\n",
       "      <td>Very Good</td>\n",
       "      <td>-</td>\n",
       "      <td>-</td>\n",
       "      <td>Free WiFi, Follows Covid-19 sanitation guidance</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>PubLove @ The Steam Engine, Waterloo</td>\n",
       "      <td>Hostel - 0.5km from city centre</td>\n",
       "      <td>8.0</td>\n",
       "      <td>394</td>\n",
       "      <td>Fabulous</td>\n",
       "      <td>-</td>\n",
       "      <td>-</td>\n",
       "      <td>Free WiFi, Follows Covid-19 sanitation guidance</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>St Christopher's Shepherds Bush</td>\n",
       "      <td>Hostel - 7km from city centre</td>\n",
       "      <td>7.3</td>\n",
       "      <td>772</td>\n",
       "      <td>Very Good</td>\n",
       "      <td>-</td>\n",
       "      <td>-</td>\n",
       "      <td>Free WiFi, Follows Covid-19 sanitation guidance</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>Book a Bed Hostels</td>\n",
       "      <td>Hostel - 6.9km from city centre</td>\n",
       "      <td>7.4</td>\n",
       "      <td>1255</td>\n",
       "      <td>Very Good</td>\n",
       "      <td>-</td>\n",
       "      <td>-</td>\n",
       "      <td>Free WiFi, Follows Covid-19 sanitation guidance</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20</th>\n",
       "      <td>Selina Camden</td>\n",
       "      <td>Hostel - 5.5km from city centre</td>\n",
       "      <td>8.9</td>\n",
       "      <td>50</td>\n",
       "      <td>Fabulous</td>\n",
       "      <td>-</td>\n",
       "      <td>-</td>\n",
       "      <td>Free WiFi, Follows Covid-19 sanitation guidance</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21</th>\n",
       "      <td>PubLove @ The Crown, Battersea</td>\n",
       "      <td>Hostel - 4.7km from city centre</td>\n",
       "      <td>7.5</td>\n",
       "      <td>301</td>\n",
       "      <td>Very Good</td>\n",
       "      <td>-</td>\n",
       "      <td>-</td>\n",
       "      <td>Free WiFi, Follows Covid-19 sanitation guidance</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22</th>\n",
       "      <td>Kensal Green Backpackers</td>\n",
       "      <td>Hostel - 8.2km from city centre</td>\n",
       "      <td>5.0</td>\n",
       "      <td>3710</td>\n",
       "      <td>Rating</td>\n",
       "      <td>-</td>\n",
       "      <td>-</td>\n",
       "      <td>Free WiFi, Follows Covid-19 sanitation guidance</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23</th>\n",
       "      <td>Hootananny Hostel</td>\n",
       "      <td>Hostel - 5km from city centre</td>\n",
       "      <td>7.6</td>\n",
       "      <td>1511</td>\n",
       "      <td>Very Good</td>\n",
       "      <td>-</td>\n",
       "      <td>-</td>\n",
       "      <td>Free WiFi, Follows Covid-19 sanitation guidance</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24</th>\n",
       "      <td>Hostelle London</td>\n",
       "      <td>Hostel - 5.1km from city centre</td>\n",
       "      <td>8.7</td>\n",
       "      <td>11</td>\n",
       "      <td>Fabulous</td>\n",
       "      <td>-</td>\n",
       "      <td>-</td>\n",
       "      <td>Free WiFi, Follows Covid-19 sanitation guidance</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25</th>\n",
       "      <td>PubLove @ The White Ferry, Victoria</td>\n",
       "      <td>Hostel - 2.4km from city centre</td>\n",
       "      <td>7.3</td>\n",
       "      <td>338</td>\n",
       "      <td>Very Good</td>\n",
       "      <td>-</td>\n",
       "      <td>-</td>\n",
       "      <td>Free WiFi, Follows Covid-19 sanitation guidance</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>26</th>\n",
       "      <td>Elmwood Hotel</td>\n",
       "      <td>Hotel - 3.2km from city centre</td>\n",
       "      <td>7.7</td>\n",
       "      <td>128</td>\n",
       "      <td>Very Good</td>\n",
       "      <td>-</td>\n",
       "      <td>-</td>\n",
       "      <td>Free WiFi, Follows Covid-19 sanitation guidance</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>27</th>\n",
       "      <td>London Waterloo Hostel</td>\n",
       "      <td>Hostel - 0.7km from city centre</td>\n",
       "      <td>5.5</td>\n",
       "      <td>2534</td>\n",
       "      <td>Rating</td>\n",
       "      <td>-</td>\n",
       "      <td>-</td>\n",
       "      <td>Free WiFi, Follows Covid-19 sanitation guidance</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>28</th>\n",
       "      <td>PubLove @ The Rose &amp; Crown</td>\n",
       "      <td>Hostel - 1.6km from city centre</td>\n",
       "      <td>7.5</td>\n",
       "      <td>189</td>\n",
       "      <td>Very Good</td>\n",
       "      <td>-</td>\n",
       "      <td>-</td>\n",
       "      <td>Free WiFi, Follows Covid-19 sanitation guidance</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>29</th>\n",
       "      <td>Tony's House Hotel</td>\n",
       "      <td>Hotel - 4.3km from city centre</td>\n",
       "      <td>8.2</td>\n",
       "      <td>422</td>\n",
       "      <td>Fabulous</td>\n",
       "      <td>-</td>\n",
       "      <td>-</td>\n",
       "      <td>Free WiFi, Follows Covid-19 sanitation guidance</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                Hostel_Name        Distance fron city centre  \\\n",
       "0               Wombat's City Hostel London  Hostel - 3.6km from city centre   \n",
       "1                  St Christopher's Village  Hostel - 1.8km from city centre   \n",
       "2                      Urbany Hostel London  Hostel - 5.4km from city centre   \n",
       "3                          NX London Hostel  Hostel - 6.1km from city centre   \n",
       "4                          Generator London    Hostel - 3km from city centre   \n",
       "5         Safestay London Elephant & Castle  Hostel - 1.7km from city centre   \n",
       "6                            Phoenix Hostel  Hostel - 4.2km from city centre   \n",
       "7   Safestay London Kensington Holland Park  Hostel - 5.8km from city centre   \n",
       "8                        No.8 Seven Sisters    Hostel - 9km from city centre   \n",
       "9                   Queen Elizabeth Chelsea  Hostel - 5.7km from city centre   \n",
       "10     St Christopher's Inn - London Bridge  Hostel - 1.8km from city centre   \n",
       "11             St Christopher's Hammersmith  Hostel - 7.5km from city centre   \n",
       "12             International Students House  Hostel - 3.3km from city centre   \n",
       "13                  St Christopher's Camden  Hostel - 4.3km from city centre   \n",
       "14               St Christopher's Greenwich  Hostel - 7.6km from city centre   \n",
       "15                        Bell House Hostel  Hostel - 4.2km from city centre   \n",
       "16                  Saint James Backpackers  Hostel - 5.5km from city centre   \n",
       "17     PubLove @ The Steam Engine, Waterloo  Hostel - 0.5km from city centre   \n",
       "18          St Christopher's Shepherds Bush    Hostel - 7km from city centre   \n",
       "19                       Book a Bed Hostels  Hostel - 6.9km from city centre   \n",
       "20                            Selina Camden  Hostel - 5.5km from city centre   \n",
       "21           PubLove @ The Crown, Battersea  Hostel - 4.7km from city centre   \n",
       "22                 Kensal Green Backpackers  Hostel - 8.2km from city centre   \n",
       "23                        Hootananny Hostel    Hostel - 5km from city centre   \n",
       "24                          Hostelle London  Hostel - 5.1km from city centre   \n",
       "25      PubLove @ The White Ferry, Victoria  Hostel - 2.4km from city centre   \n",
       "26                            Elmwood Hotel   Hotel - 3.2km from city centre   \n",
       "27                   London Waterloo Hostel  Hostel - 0.7km from city centre   \n",
       "28               PubLove @ The Rose & Crown  Hostel - 1.6km from city centre   \n",
       "29                       Tony's House Hotel   Hotel - 4.3km from city centre   \n",
       "\n",
       "   Ratings Total_reviews Overall Reviews Privates from price Dorms from price  \\\n",
       "0      9.0        14896           Superb                   -                -   \n",
       "1      7.9        12155        Very Good                   -                -   \n",
       "2      9.4          780           Superb                   -                -   \n",
       "3      8.3         1885         Fabulous                   -                -   \n",
       "4      7.5         7500        Very Good                   -                -   \n",
       "5      7.5         4957        Very Good                   -                -   \n",
       "6      7.6         4126        Very Good                   -                -   \n",
       "7      7.1         1528        Very Good                   -                -   \n",
       "8      5.7         4010           Rating                   -                -   \n",
       "9      7.4         3480        Very Good                   -                -   \n",
       "10     8.0         3506         Fabulous                   -                -   \n",
       "11     7.7         4243        Very Good                   -                -   \n",
       "12     9.3         1035           Superb                   -                -   \n",
       "13     7.0         4035        Very Good                   -                -   \n",
       "14     7.5         3350        Very Good                   -                -   \n",
       "15     7.6           60        Very Good                   -                -   \n",
       "16     7.5         1884        Very Good                   -                -   \n",
       "17     8.0          394         Fabulous                   -                -   \n",
       "18     7.3          772        Very Good                   -                -   \n",
       "19     7.4         1255        Very Good                   -                -   \n",
       "20     8.9           50         Fabulous                   -                -   \n",
       "21     7.5          301        Very Good                   -                -   \n",
       "22     5.0         3710           Rating                   -                -   \n",
       "23     7.6         1511        Very Good                   -                -   \n",
       "24     8.7           11         Fabulous                   -                -   \n",
       "25     7.3          338        Very Good                   -                -   \n",
       "26     7.7          128        Very Good                   -                -   \n",
       "27     5.5         2534           Rating                   -                -   \n",
       "28     7.5          189        Very Good                   -                -   \n",
       "29     8.2          422         Fabulous                   -                -   \n",
       "\n",
       "                                         Facilities  \n",
       "0   Free WiFi, Follows Covid-19 sanitation guidance  \n",
       "1   Free WiFi, Follows Covid-19 sanitation guidance  \n",
       "2   Free WiFi, Follows Covid-19 sanitation guidance  \n",
       "3   Free WiFi, Follows Covid-19 sanitation guidance  \n",
       "4   Free WiFi, Follows Covid-19 sanitation guidance  \n",
       "5   Free WiFi, Follows Covid-19 sanitation guidance  \n",
       "6   Free WiFi, Follows Covid-19 sanitation guidance  \n",
       "7   Free WiFi, Follows Covid-19 sanitation guidance  \n",
       "8   Free WiFi, Follows Covid-19 sanitation guidance  \n",
       "9   Free WiFi, Follows Covid-19 sanitation guidance  \n",
       "10  Free WiFi, Follows Covid-19 sanitation guidance  \n",
       "11  Free WiFi, Follows Covid-19 sanitation guidance  \n",
       "12  Free WiFi, Follows Covid-19 sanitation guidance  \n",
       "13  Free WiFi, Follows Covid-19 sanitation guidance  \n",
       "14  Free WiFi, Follows Covid-19 sanitation guidance  \n",
       "15  Free WiFi, Follows Covid-19 sanitation guidance  \n",
       "16  Free WiFi, Follows Covid-19 sanitation guidance  \n",
       "17  Free WiFi, Follows Covid-19 sanitation guidance  \n",
       "18  Free WiFi, Follows Covid-19 sanitation guidance  \n",
       "19  Free WiFi, Follows Covid-19 sanitation guidance  \n",
       "20  Free WiFi, Follows Covid-19 sanitation guidance  \n",
       "21  Free WiFi, Follows Covid-19 sanitation guidance  \n",
       "22  Free WiFi, Follows Covid-19 sanitation guidance  \n",
       "23  Free WiFi, Follows Covid-19 sanitation guidance  \n",
       "24  Free WiFi, Follows Covid-19 sanitation guidance  \n",
       "25  Free WiFi, Follows Covid-19 sanitation guidance  \n",
       "26  Free WiFi, Follows Covid-19 sanitation guidance  \n",
       "27  Free WiFi, Follows Covid-19 sanitation guidance  \n",
       "28  Free WiFi, Follows Covid-19 sanitation guidance  \n",
       "29  Free WiFi, Follows Covid-19 sanitation guidance  "
      ]
     },
     "execution_count": 80,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
